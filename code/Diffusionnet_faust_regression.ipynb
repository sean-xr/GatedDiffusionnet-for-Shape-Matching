{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4614,"status":"ok","timestamp":1704802324172,"user":{"displayName":"Rui Xiao","userId":"00023545256536816003"},"user_tz":-60},"id":"ZAxa0jY3eSgR","outputId":"330c7037-4b70-4920-9d23-5b82a3c4d801"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":742,"status":"ok","timestamp":1704802326985,"user":{"displayName":"Rui Xiao","userId":"00023545256536816003"},"user_tz":-60},"id":"dnect8Qii2oK","outputId":"c16e1bd7-6722-46af-9cbf-a33c6002c6ae"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/P3DCV/Diff-FMAPs/code\n"]}],"source":["%cd \"/content/drive/MyDrive/P3DCV/Diff-FMAPs/code/\"\n","import sys\n","sys.path.insert(0, \"/content/drive/MyDrive/P3DCV/Diff-FMAPs/code/\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57688,"status":"ok","timestamp":1704801908198,"user":{"displayName":"Rui Xiao","userId":"00023545256536816003"},"user_tz":-60},"id":"PaGxAVjdeZ1X","outputId":"1ce9d109-59e1-4906-9e9e-2577ef394f8f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n","Collecting plyfile\n","  Downloading plyfile-1.0.3-py3-none-any.whl (23 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from plyfile) (1.23.5)\n","Installing collected packages: plyfile\n","Successfully installed plyfile-1.0.3\n","Collecting polyscope\n","  Downloading polyscope-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from polyscope) (1.23.5)\n","Installing collected packages: polyscope\n","Successfully installed polyscope-2.0.0\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n","Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.10/dist-packages (3.2.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (4.5.0)\n","Collecting libigl\n","  Downloading libigl-2.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from libigl) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from libigl) (1.11.4)\n","Installing collected packages: libigl\n","Successfully installed libigl-2.5.0\n","Collecting potpourri3d\n","  Downloading potpourri3d-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (869 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m869.3/869.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from potpourri3d) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from potpourri3d) (1.11.4)\n","Installing collected packages: potpourri3d\n","Successfully installed potpourri3d-1.0.0\n","Collecting robust_laplacian\n","  Downloading robust_laplacian-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (390 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.1/390.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from robust_laplacian) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from robust_laplacian) (1.11.4)\n","Installing collected packages: robust_laplacian\n","Successfully installed robust_laplacian-0.2.7\n"]}],"source":["!pip install joblib\n","!pip install plyfile\n","!pip install polyscope\n","!pip install scikit-learn\n","!pip install scipy\n","!pip install threadpoolctl\n","!pip install tqdm\n","!pip install typing-extensions\n","!pip install libigl\n","!pip install potpourri3d\n","!pip install robust_laplacian"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"52OPYE85ecb1","executionInfo":{"status":"ok","timestamp":1704802332929,"user_tz":-60,"elapsed":2631,"user":{"displayName":"Rui Xiao","userId":"00023545256536816003"}}},"outputs":[],"source":["import igl\n","import numpy as np\n","import os\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from tqdm import tqdm\n","import numpy as np\n","from torch.utils.data import DataLoader\n","from Diffusionnet_MPIFAUST_dataset import DiffusionnetFaustDataset2\n","from model_diffusionnet import FunctionalMapCorrespondenceWithDiffusionNetFeatures\n","\n","from tqdm import tqdm\n","\n","import torch\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"J6-5H-a_Uumi","executionInfo":{"status":"ok","timestamp":1704802336066,"user_tz":-60,"elapsed":3,"user":{"displayName":"Rui Xiao","userId":"00023545256536816003"}}},"outputs":[],"source":["dtype = torch.float32\n","# model\n","input_features = 'xyz' # one of ['xyz', 'hks']\n","k_eig = 128\n","\n","# functional maps settings\n","n_fmap = 30 # number of eigenvectors used within functional maps\n","n_feat = 100 # dimension of features computed by DiffusionNet extractor\n","lambda_param = 1e-3 # functional map block regularization parameter\n","\n","# training settings\n","train = True\n","n_epoch = 50\n","lr = 5e-4\n","decay_every = 9999\n","decay_rate = 0.1\n","augment_random_rotate = (input_features == 'xyz')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3523,"status":"ok","timestamp":1704802343070,"user":{"displayName":"Rui Xiao","userId":"00023545256536816003"},"user_tz":-60},"id":"f1gYZnjueep1","outputId":"61baa4aa-8466-4af9-e127-affda68e212a"},"outputs":[{"output_type":"stream","name":"stdout","text":["length of dataset: 3160\n","using dataset cache path: /content/drive/MyDrive/P3DCV/data/MPI-FAUST/cache/train.pt\n","  --> loading dataset from cache\n","length of dataset: 190\n","using dataset cache path: /content/drive/MyDrive/P3DCV/data/MPI-FAUST/cache/test.pt\n","  --> loading dataset from cache\n"]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","n_epoch = 50\n","lr = 5e-4\n","decay_every = 9999\n","decay_rate = 0.1\n","root_dir = \"/content/drive/MyDrive/P3DCV/data/\"\n","op_cache_dir = os.path.join(root_dir, \"op_cache\")\n","#defining train and test set\n","train_set = DiffusionnetFaustDataset2(root_dir, name=\"MPI-FAUST\", train=True, k_eig=k_eig, use_cache=True, op_cache_dir=op_cache_dir)\n","train_loader = DataLoader(train_set, batch_size=8, shuffle=True)\n","test_set = DiffusionnetFaustDataset2(root_dir, name=\"MPI-FAUST\", train=False, k_eig=k_eig, use_cache=True, op_cache_dir=op_cache_dir)\n","test_loader = DataLoader(test_set, batch_size=2, shuffle=True)\n","'''\n","IMPORTANT: Model Saving\n","'''\n","model_save_dir = os.path.join(root_dir, \"models\", \"diffusionet\")\n","if not os.path.exists(model_save_dir):\n","  os.makedirs(model_save_dir, exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AHmYTX9qehxc"},"outputs":[],"source":["for i, data in enumerate(train_loader):\n","  shape1, shape2 = data\n","\n","  #verts1, faces1, frames1, mass1, L1, evals1, evecs1, gradX1, gradY1, hks1 = shape1\n","  #verts2, faces2, frames2, mass2, L2, evals2, evecs2, gradX2, gradY2, hks2 = shape2\n","  *shape1, name1, basis1 = shape1\n","  *shape2, name2, basis2 = shape2\n","  print(\"basis1 shape\", basis1.shape)\n","  print(\"basis2 shape\", basis2.shape)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"TQoHDV1UGR5W","executionInfo":{"status":"ok","timestamp":1704802349512,"user_tz":-60,"elapsed":1630,"user":{"displayName":"Rui Xiao","userId":"00023545256536816003"}}},"outputs":[],"source":["model = FunctionalMapCorrespondenceWithDiffusionNetFeatures(\n","                        n_feat= n_feat,#multi-head: 2*n_feat, single-head: n_feat\n","                        input_features=input_features,\n","                        lambda_param=lambda_param\n","                        )\n","\n","\n","model = model.to(device)\n","optim = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.001)\n","l1_loss = torch.nn.L1Loss(reduction='mean')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A5SiGhoGeGDN","outputId":"ef600ee2-f5e3-4181-dac6-33ae13f1cf1e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","training eucl loss for epoch0: 432.71260932246344\n","training elastic loss for epoch0: 0.5443553938895841\n","training total loss for epoch0: 433.2569652509086\n","validation eucl loss for epoch0: 39.99564309371145\n","validation elastic loss for epoch0: 0.7213466801141438\n","validation total loss for epoch0: 40.716989617598685\n","\n","training eucl loss for epoch1: 91.27370835316331\n","training elastic loss for epoch1: 0.790992936303344\n","training total loss for epoch1: 92.06470137970356\n","validation eucl loss for epoch1: 41.930756498637955\n","validation elastic loss for epoch1: 0.8082053843297456\n","validation total loss for epoch1: 42.73896175183748\n","\n","training eucl loss for epoch2: 72.43614970340005\n","training elastic loss for epoch2: 0.8429390335384803\n","training total loss for epoch2: 73.27908869876137\n","validation eucl loss for epoch2: 35.88742270218699\n","validation elastic loss for epoch2: 0.8408472525446038\n","validation total loss for epoch2: 36.72827003880551\n","\n","training eucl loss for epoch3: 62.57115431194064\n","training elastic loss for epoch3: 0.8694984096515028\n","training total loss for epoch3: 63.44065282314639\n","validation eucl loss for epoch3: 33.58446323997096\n","validation elastic loss for epoch3: 0.869993447630029\n","validation total loss for epoch3: 34.45445683127955\n","\n","training eucl loss for epoch4: 55.87001420033129\n","training elastic loss for epoch4: 0.8880208673356454\n","training total loss for epoch4: 56.75803506585616\n","validation eucl loss for epoch4: 30.24592144614772\n","validation elastic loss for epoch4: 0.8734272988219011\n","validation total loss for epoch4: 31.119348666542454\n","\n","training eucl loss for epoch5: 50.82362637097322\n","training elastic loss for epoch5: 0.9020055066181134\n","training total loss for epoch5: 51.725631984276106\n","validation eucl loss for epoch5: 32.13145651566355\n","validation elastic loss for epoch5: 0.8770502868451571\n","validation total loss for epoch5: 33.00850685521176\n","\n","training eucl loss for epoch6: 46.9761875490599\n","training elastic loss for epoch6: 0.9128825774675683\n","training total loss for epoch6: 47.88907011007961\n","validation eucl loss for epoch6: 31.470358055516293\n","validation elastic loss for epoch6: 0.8935241291397497\n","validation total loss for epoch6: 32.36388222543817\n","\n","training eucl loss for epoch7: 43.56719264742694\n","training elastic loss for epoch7: 0.9231092869480954\n","training total loss for epoch7: 44.49030198688749\n","validation eucl loss for epoch7: 31.732180806210167\n","validation elastic loss for epoch7: 0.9030883117725975\n","validation total loss for epoch7: 32.63526924534848\n","\n","training eucl loss for epoch8: 40.53934894996353\n","training elastic loss for epoch8: 0.9326270129107221\n","training total loss for epoch8: 41.471975930129425\n","validation eucl loss for epoch8: 31.478055411890935\n","validation elastic loss for epoch8: 0.9042239082487006\n","validation total loss for epoch8: 32.38227938601845\n","\n","training eucl loss for epoch9: 37.85816302722014\n","training elastic loss for epoch9: 0.9350276759908169\n","training total loss for epoch9: 38.79319074606594\n","validation eucl loss for epoch9: 32.893696554083576\n","validation elastic loss for epoch9: 0.9089179572306181\n","validation total loss for epoch9: 33.80261465373792\n","\n","training eucl loss for epoch10: 35.49295321114455\n","training elastic loss for epoch10: 0.930947382993336\n","training total loss for epoch10: 36.42390061873424\n","validation eucl loss for epoch10: 31.717758861340975\n","validation elastic loss for epoch10: 0.904493879017077\n","validation total loss for epoch10: 32.62225279557077\n","\n","training eucl loss for epoch11: 33.2823248319988\n","training elastic loss for epoch11: 0.9273991547053373\n","training total loss for epoch11: 34.20972401582742\n","validation eucl loss for epoch11: 32.189185152555766\n","validation elastic loss for epoch11: 0.9265232230487622\n","validation total loss for epoch11: 33.11570838125129\n","\n","training eucl loss for epoch12: 31.40366763827167\n","training elastic loss for epoch12: 0.9289780977406079\n","training total loss for epoch12: 32.332645749442186\n","validation eucl loss for epoch12: 31.68661067360326\n","validation elastic loss for epoch12: 0.9027224659919739\n","validation total loss for epoch12: 32.58933312265496\n","\n","training eucl loss for epoch13: 29.736798834498924\n","training elastic loss for epoch13: 0.929179102408735\n","training total loss for epoch13: 30.665977970557876\n","validation eucl loss for epoch13: 32.10520959151419\n","validation elastic loss for epoch13: 0.8952196485117863\n","validation total loss for epoch13: 33.00042929398386\n","\n","training eucl loss for epoch14: 28.393822870375235\n","training elastic loss for epoch14: 0.9294145164610464\n","training total loss for epoch14: 29.32323739739913\n","validation eucl loss for epoch14: 32.1538354974044\n","validation elastic loss for epoch14: 0.8935969145674455\n","validation total loss for epoch14: 33.0474325079667\n","\n","training eucl loss for epoch15: 27.331370433372786\n","training elastic loss for epoch15: 0.9252244623401497\n","training total loss for epoch15: 28.256594877605195\n","validation eucl loss for epoch15: 31.959729606226873\n","validation elastic loss for epoch15: 0.8997749359984147\n","validation total loss for epoch15: 32.85950457924291\n","\n","training eucl loss for epoch16: 26.094308307502843\n","training elastic loss for epoch16: 0.92409304999098\n","training total loss for epoch16: 27.018401375299767\n","validation eucl loss for epoch16: 30.633569255628085\n","validation elastic loss for epoch16: 0.8929447117604707\n","validation total loss for epoch16: 31.52651381241648\n","\n","training eucl loss for epoch17: 25.219670756859117\n","training elastic loss for epoch17: 0.9217358812501159\n","training total loss for epoch17: 26.141406645955918\n","validation eucl loss for epoch17: 30.17577257658306\n","validation elastic loss for epoch17: 0.8788412301163925\n","validation total loss for epoch17: 31.05461389642013\n","\n","training eucl loss for epoch18: 24.31776662416096\n","training elastic loss for epoch18: 0.9167730038679098\n","training total loss for epoch18: 25.234539625916298\n","validation eucl loss for epoch18: 31.474009343197473\n","validation elastic loss for epoch18: 0.8812870446004366\n","validation total loss for epoch18: 32.35529628552889\n","\n","training eucl loss for epoch19: 23.67560602501978\n","training elastic loss for epoch19: 0.9123489185224606\n","training total loss for epoch19: 24.58795494852187\n","validation eucl loss for epoch19: 30.60907241419742\n","validation elastic loss for epoch19: 0.8776840159767553\n","validation total loss for epoch19: 31.486756294652036\n","\n","training eucl loss for epoch20: 22.93727495217625\n","training elastic loss for epoch20: 0.9078574550302723\n","training total loss for epoch20: 23.845132393173024\n","validation eucl loss for epoch20: 31.132996970728826\n","validation elastic loss for epoch20: 0.8654089250062641\n","validation total loss for epoch20: 31.998405817935343\n"]}],"source":["#single head training loop\n","\n","epoch_train_loss = []\n","epoch_val_loss = []\n","for epoch in range(n_epoch):\n","    train_losses = []\n","    train_elastic_losses = []\n","    train_total_losses = []\n","    val_losses = []\n","    val_elastic_losses = []\n","    val_total_losses = []\n","    faust_losses = []\n","    #metrics = []\n","    # Training single Epoch\n","    model.train()\n","    for i, data in enumerate(train_loader):\n","        shapeA, shapeB = data\n","        *shapeA, nameA, gtbasisA = shapeA\n","        *shapeB, nameB, gtbasisB = shapeB\n","        shapeA, shapeB = [x.to(device) for x in shapeA], [x.to(device) for x in shapeB]\n","        gtbasisA, gtbasisB = gtbasisA.to(device).to(torch.float32), gtbasisB.to(device).to(torch.float32)\n","        optim.zero_grad()\n","\n","        # Obtaining predicted basis\n","        basisA, basisB = model(shapeA, shapeB)\n","\n","        # Computing optimal transformation\n","        pseudo_inv_A = torch.pinverse(basisA)\n","        C_opt = torch.matmul(pseudo_inv_A, basisB)\n","        opt_A = torch.matmul(basisA, C_opt)\n","\n","        # SoftMap\n","        dist_matrix = torch.cdist(opt_A, basisB)\n","        s_max = torch.nn.Softmax(dim=1)\n","        s_max_matrix = s_max(-dist_matrix)\n","\n","        # Basis Loss\n","        vertsB = shapeB[0] #get vertsB out\n","        eucl_loss = torch.sum(torch.square(torch.matmul(s_max_matrix, vertsB) - vertsB))\n","\n","        # Elastic Loss\n","        #elastic_loss = l1_loss(basisA, gtbasisA) + l1_loss(basisB, gtbasisB)\n","        l1_norm = 0.4 * torch.abs(basisA).mean() + 0.4 * torch.abs(basisB).mean()\n","        #metric = torch.mean(torch.square(s_max_matrix - torch.identity(s_max_matrix.shape[0]))) # measuring how well we are approximating the ground-truth correspondence\n","        # Back Prop\n","        #total_loss = eucl_loss +  elastic_loss\n","        total_loss = eucl_loss + l1_norm\n","        total_loss.backward()\n","        #eucl_loss.backward()\n","        optim.step()\n","        train_losses.append(eucl_loss.detach().item())\n","        train_elastic_losses.append(l1_norm.detach().item())\n","        #train_elastic_losses.append(elastic_loss.detach().item())\n","        train_total_losses.append(total_loss.detach().item())\n","        #metrics.append(metric.detach().item())\n","\n","    model.eval()\n","    with torch.no_grad():\n","      for i, data in enumerate(test_loader):\n","          shapeA, shapeB = data\n","          *shapeA, nameA, gtbasisA = shapeA\n","          *shapeB, nameB, gtbasisB = shapeB\n","          shapeA, shapeB = [x.to(device) for x in shapeA], [x.to(device) for x in shapeB]\n","          gtbasisA, gtbasisB = gtbasisA.to(device).to(torch.float32), gtbasisB.to(device).to(torch.float32)\n","\n","          basisA, basisB = model(shapeA, shapeB)\n","\n","          pseudo_inv_A = torch.pinverse(basisA)\n","          C_opt = torch.matmul(pseudo_inv_A, basisB)\n","          opt_A = torch.matmul(basisA, C_opt)\n","          # SoftMap\n","          dist_matrix = torch.cdist(opt_A, basisB)\n","          s_max = torch.nn.Softmax(dim=1)\n","          s_max_matrix = s_max(-dist_matrix)\n","\n","          # Basis Loss\n","          vertsB = shapeB[0]\n","          val_eucl_loss = torch.sum(torch.square(torch.matmul(s_max_matrix, vertsB) - vertsB))\n","          #val_elastic_loss = l1_loss(basisA, gtbasisA) + l1_loss(basisB, gtbasisB)\n","          val_l1_norm = 0.4 * torch.abs(basisA).mean() + 0.4 * torch.abs(basisB).mean()\n","          val_total_loss = val_eucl_loss + val_l1_norm\n","          #val_total_loss = val_eucl_loss + val_elastic_loss\n","          val_losses.append(val_eucl_loss.detach().item())\n","          #val_elastic_losses.append(val_elastic_loss.detach().item())\n","          val_elastic_losses.append(val_l1_norm.detach().item())\n","          val_total_losses.append(val_total_loss.detach().item())\n","\n","    ave_train_loss = sum(train_losses) / len(train_losses)\n","    ave_train_elastic_loss = sum(train_elastic_losses) / len(train_elastic_losses)\n","    ave_train_total_loss = sum(train_total_losses) / len(train_total_losses)\n","    ave_val_loss = sum(val_losses) / len(val_losses)\n","    ave_val_elastic_loss = sum(val_elastic_losses) / len(val_elastic_losses)\n","    ave_val_total_loss = sum(val_total_losses) / len(val_total_losses)\n","    #ave_metric = sum(metrics) / len(metrics)\n","    print()\n","    print(f\"training eucl loss for epoch{epoch}:\", ave_train_loss)\n","    print(f\"training elastic loss for epoch{epoch}:\", ave_train_elastic_loss)\n","    print(f\"training total loss for epoch{epoch}:\", ave_train_total_loss)\n","    print(f\"validation eucl loss for epoch{epoch}:\", ave_val_loss)\n","    print(f\"validation elastic loss for epoch{epoch}:\", ave_val_elastic_loss)\n","    print(f\"validation total loss for epoch{epoch}:\", ave_val_total_loss)\n","    #print(f\"training metric for epoch{epoch}:\", ave_metric)\n","    torch.save(model.state_dict(), os.path.join(model_save_dir, f\"train6_k_{n_feat}_epoch_{epoch}\"))\n","    epoch_train_loss.append(ave_train_loss)\n","    epoch_val_loss.append(ave_val_loss)\n","np.save(f\"/content/drive/MyDrive/P3DCV/losses/train/diffusionnet6_k_{n_feat}.npy\", np.array(epoch_train_loss))\n","np.save(f\"/content/drive/MyDrive/P3DCV/losses/val/diffusionnet6_k_{n_feat}.npy\", np.array(epoch_val_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1088744,"status":"error","timestamp":1704238883899,"user":{"displayName":"Rui Xiao","userId":"00023545256536816003"},"user_tz":-60},"id":"FDpGiE2HG6Lk","outputId":"ad2a5348-1fb9-41b7-f12c-a6ab378bd877"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","training eucl loss for epoch0: 418.37023935438714\n","training elastic loss for epoch0: 0.8814719086960902\n","training total loss for epoch0: 418.5465338791473\n","validation eucl loss for epoch0: 40.53102505332545\n","validation elastic loss for epoch0: 0.8309022859523171\n","validation total loss for epoch0: 40.69720555355674\n","\n","training eucl loss for epoch1: 89.80323909324936\n","training elastic loss for epoch1: 0.8643974907790558\n","training total loss for epoch1: 89.97611844992336\n","validation eucl loss for epoch1: 46.2820611652575\n","validation elastic loss for epoch1: 0.8302119725628903\n","validation total loss for epoch1: 46.448103693911904\n","\n","training eucl loss for epoch2: 70.85475842439676\n","training elastic loss for epoch2: 0.8617582156688353\n","training total loss for epoch2: 71.02711002977588\n","validation eucl loss for epoch2: 47.74801370721114\n","validation elastic loss for epoch2: 0.8298683831566258\n","validation total loss for epoch2: 47.91398712961297\n","\n","training eucl loss for epoch3: 60.70216915275477\n","training elastic loss for epoch3: 0.8612159323088731\n","training total loss for epoch3: 60.874412401416635\n","validation eucl loss for epoch3: 43.72523080926192\n","validation elastic loss for epoch3: 0.829576419529162\n","validation total loss for epoch3: 43.8911461679559\n","\n","training eucl loss for epoch4: 54.03796826133245\n","training elastic loss for epoch4: 0.8609449932846842\n","training total loss for epoch4: 54.21015721574614\n","validation eucl loss for epoch4: 39.78726706253855\n","validation elastic loss for epoch4: 0.8291774661917436\n","validation total loss for epoch4: 39.95310247320878\n","\n","training eucl loss for epoch5: 49.13776650730568\n","training elastic loss for epoch5: 0.8607559053203727\n","training total loss for epoch5: 49.3099176431004\n","validation eucl loss for epoch5: 38.131081470690276\n","validation elastic loss for epoch5: 0.8292050606326054\n","validation total loss for epoch5: 38.296922262091385\n","\n","training eucl loss for epoch6: 45.37865080048766\n","training elastic loss for epoch6: 0.8606032564670225\n","training total loss for epoch6: 45.550771447676645\n","validation eucl loss for epoch6: 38.0396693581029\n","validation elastic loss for epoch6: 0.8289804985648708\n","validation total loss for epoch6: 38.20546541715923\n","\n","training eucl loss for epoch7: 42.49653074047234\n","training elastic loss for epoch7: 0.8604480566857736\n","training total loss for epoch7: 42.66862029063551\n","validation eucl loss for epoch7: 36.37964953372353\n","validation elastic loss for epoch7: 0.8287257338825025\n","validation total loss for epoch7: 36.54539461637798\n","\n","training eucl loss for epoch8: 39.891880383069\n","training elastic loss for epoch8: 0.8602945993218241\n","training total loss for epoch8: 40.06393931907944\n","validation eucl loss for epoch8: 36.20687713623047\n","validation elastic loss for epoch8: 0.8286796877258702\n","validation total loss for epoch8: 36.37261308368883\n","\n","training eucl loss for epoch9: 37.62498478949824\n","training elastic loss for epoch9: 0.8601621810393998\n","training total loss for epoch9: 37.79701726406435\n","validation eucl loss for epoch9: 36.139022525988125\n","validation elastic loss for epoch9: 0.8284997482048838\n","validation total loss for epoch9: 36.30472251490543\n","\n","training eucl loss for epoch10: 35.62128886935077\n","training elastic loss for epoch10: 0.8600494701651078\n","training total loss for epoch10: 35.793298726142204\n","validation eucl loss for epoch10: 36.34485708537855\n","validation elastic loss for epoch10: 0.8284644440600747\n","validation total loss for epoch10: 36.51055004722193\n","\n","training eucl loss for epoch11: 33.763551668577556\n","training elastic loss for epoch11: 0.8599623820449732\n","training total loss for epoch11: 33.93554405019253\n","validation eucl loss for epoch11: 35.72729423924496\n","validation elastic loss for epoch11: 0.8284897070181997\n","validation total loss for epoch11: 35.89299205980803\n","\n","training eucl loss for epoch12: 32.0851769217962\n","training elastic loss for epoch12: 0.859882958025872\n","training total loss for epoch12: 32.257153479660616\n","validation eucl loss for epoch12: 34.1590830351177\n","validation elastic loss for epoch12: 0.8285920387820194\n","validation total loss for epoch12: 34.324801455046\n","\n","training eucl loss for epoch13: 30.325348344633852\n","training elastic loss for epoch13: 0.8598084259636795\n","training total loss for epoch13: 30.497310049322586\n","validation eucl loss for epoch13: 33.48899728875411\n","validation elastic loss for epoch13: 0.8283376122775831\n","validation total loss for epoch13: 33.65466481258995\n","\n","training eucl loss for epoch14: 28.746112065375605\n","training elastic loss for epoch14: 0.8597517193118228\n","training total loss for epoch14: 28.918062437033353\n","validation eucl loss for epoch14: 33.9513442591617\n","validation elastic loss for epoch14: 0.8283351672323127\n","validation total loss for epoch14: 34.11701128106368\n","\n","training eucl loss for epoch15: 27.418721148333972\n","training elastic loss for epoch15: 0.859699611271484\n","training total loss for epoch15: 27.59066107061845\n","validation eucl loss for epoch15: 32.70558919404682\n","validation elastic loss for epoch15: 0.8282765162618537\n","validation total loss for epoch15: 32.87124445061934\n","\n","training eucl loss for epoch16: 26.160536391825616\n","training elastic loss for epoch16: 0.8596469957617264\n","training total loss for epoch16: 26.332465782648402\n","validation eucl loss for epoch16: 31.569006407888313\n","validation elastic loss for epoch16: 0.8281349671514411\n","validation total loss for epoch16: 31.734633315236945\n","\n","training eucl loss for epoch17: 25.183780134176907\n","training elastic loss for epoch17: 0.859617947174024\n","training total loss for epoch17: 25.355703677406794\n","validation eucl loss for epoch17: 30.944720760144687\n","validation elastic loss for epoch17: 0.8282608038500736\n","validation total loss for epoch17: 31.110373025191457\n","\n","training eucl loss for epoch18: 24.359628397301783\n","training elastic loss for epoch18: 0.8595766366282596\n","training total loss for epoch18: 24.531543683402145\n","validation eucl loss for epoch18: 30.295172078985917\n","validation elastic loss for epoch18: 0.8279301624549062\n","validation total loss for epoch18: 30.4607581289191\n","\n","training eucl loss for epoch19: 23.646697457229035\n","training elastic loss for epoch19: 0.8595155263248878\n","training total loss for epoch19: 23.818600526640687\n","validation eucl loss for epoch19: 30.907256015978362\n","validation elastic loss for epoch19: 0.8279885662229438\n","validation total loss for epoch19: 31.0728537910863\n","\n","training eucl loss for epoch20: 22.8157078320467\n","training elastic loss for epoch20: 0.859456066391136\n","training total loss for epoch20: 22.98759900346587\n","validation eucl loss for epoch20: 30.285586748625104\n","validation elastic loss for epoch20: 0.828100523823186\n","validation total loss for epoch20: 30.451206769441303\n","\n","training eucl loss for epoch21: 22.215364118165606\n","training elastic loss for epoch21: 0.8594130971763707\n","training total loss for epoch21: 22.38724670893029\n","validation eucl loss for epoch21: 29.886348222431383\n","validation elastic loss for epoch21: 0.8280295233977468\n","validation total loss for epoch21: 30.05195416902241\n","\n","training eucl loss for epoch22: 21.596927435186846\n","training elastic loss for epoch22: 0.8594046989573708\n","training total loss for epoch22: 21.768808369696895\n","validation eucl loss for epoch22: 29.637691196642425\n","validation elastic loss for epoch22: 0.8280110861125746\n","validation total loss for epoch22: 29.8032934088456\n","\n","training eucl loss for epoch23: 21.15332050564923\n","training elastic loss for epoch23: 0.8593294095389451\n","training total loss for epoch23: 21.325186369690712\n","validation eucl loss for epoch23: 28.970048362330388\n","validation elastic loss for epoch23: 0.8278086505438152\n","validation total loss for epoch23: 29.13561003835578\n","\n","training eucl loss for epoch24: 20.675950540470172\n","training elastic loss for epoch24: 0.8592939013167272\n","training total loss for epoch24: 20.847809311106236\n","validation eucl loss for epoch24: 29.200899445383172\n","validation elastic loss for epoch24: 0.8278294789163689\n","validation total loss for epoch24: 29.366465357730263\n","\n","training eucl loss for epoch25: 20.269250985640515\n","training elastic loss for epoch25: 0.8592545364476457\n","training total loss for epoch25: 20.441101914417896\n","validation eucl loss for epoch25: 29.228255783884148\n","validation elastic loss for epoch25: 0.8278329472792776\n","validation total loss for epoch25: 29.393822419015986\n","\n","training eucl loss for epoch26: 19.830474785913395\n","training elastic loss for epoch26: 0.8592170153992086\n","training total loss for epoch26: 20.00231812392609\n","validation eucl loss for epoch26: 28.6194204029284\n","validation elastic loss for epoch26: 0.8278155320569088\n","validation total loss for epoch26: 28.784983484368574\n","\n","training eucl loss for epoch27: 19.47758546177345\n","training elastic loss for epoch27: 0.8591737351840055\n","training total loss for epoch27: 19.649420170844355\n","validation eucl loss for epoch27: 29.263835465280632\n","validation elastic loss for epoch27: 0.8277338874967475\n","validation total loss for epoch27: 29.429382123445208\n","\n","training eucl loss for epoch28: 19.036202186874196\n","training elastic loss for epoch28: 0.8591339779805534\n","training total loss for epoch28: 19.208028943025614\n","validation eucl loss for epoch28: 29.655393841392115\n","validation elastic loss for epoch28: 0.8276929146365115\n","validation total loss for epoch28: 29.820932488692435\n","\n","training eucl loss for epoch29: 18.70044376518153\n","training elastic loss for epoch29: 0.8591132124768027\n","training total loss for epoch29: 18.8722664265693\n","validation eucl loss for epoch29: 28.782049420005396\n","validation elastic loss for epoch29: 0.8276756236427709\n","validation total loss for epoch29: 28.947584473459344\n","\n","training eucl loss for epoch30: 18.37692175756527\n","training elastic loss for epoch30: 0.8590810043902337\n","training total loss for epoch30: 18.548737929138955\n","validation eucl loss for epoch30: 28.90826385899594\n","validation elastic loss for epoch30: 0.8276924879927384\n","validation total loss for epoch30: 29.073802345677425\n","\n","training eucl loss for epoch31: 18.520229513433915\n","training elastic loss for epoch31: 0.8590718453443503\n","training total loss for epoch31: 18.692043898377236\n","validation eucl loss for epoch31: 29.090796520835475\n","validation elastic loss for epoch31: 0.8276056277124505\n","validation total loss for epoch31: 29.25631762052837\n","\n","training eucl loss for epoch32: 17.87868674555911\n","training elastic loss for epoch32: 0.859044966063922\n","training total loss for epoch32: 18.050495717495302\n","validation eucl loss for epoch32: 29.42632418180767\n","validation elastic loss for epoch32: 0.827672436990236\n","validation total loss for epoch32: 29.591858632940994\n","\n","training eucl loss for epoch33: 17.568571636344814\n","training elastic loss for epoch33: 0.8590183839013305\n","training total loss for epoch33: 17.740375349793254\n","validation eucl loss for epoch33: 29.068668827257657\n","validation elastic loss for epoch33: 0.8276172844987166\n","validation total loss for epoch33: 29.234192255923624\n","\n","training eucl loss for epoch34: 17.339057318771943\n","training elastic loss for epoch34: 0.8589955793151373\n","training total loss for epoch34: 17.510856415953818\n","validation eucl loss for epoch34: 29.333740796540912\n","validation elastic loss for epoch34: 0.8277635850404438\n","validation total loss for epoch34: 29.49929333737022\n","\n","training eucl loss for epoch35: 17.18019088551968\n","training elastic loss for epoch35: 0.8589671033847182\n","training total loss for epoch35: 17.351984330672252\n","validation eucl loss for epoch35: 28.726801119352643\n","validation elastic loss for epoch35: 0.8276121453235024\n","validation total loss for epoch35: 28.892323704769737\n","\n","training eucl loss for epoch36: 16.975176304201536\n","training elastic loss for epoch36: 0.8589596369598486\n","training total loss for epoch36: 17.146968269348143\n","validation eucl loss for epoch36: 28.28749616522538\n","validation elastic loss for epoch36: 0.8275507462652106\n","validation total loss for epoch36: 28.453006242450915\n","\n","training eucl loss for epoch37: 16.739031924477107\n","training elastic loss for epoch37: 0.8589088815677015\n","training total loss for epoch37: 16.910813667200788\n","validation eucl loss for epoch37: 28.534419451261822\n","validation elastic loss for epoch37: 0.8274614779572738\n","validation total loss for epoch37: 28.699911719874333\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-7ef971cc70ec>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Back Prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meucl_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0melastic_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;31m#eucl_loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Multi-head Training Loop\n","epoch_train_loss = []\n","epoch_val_loss = []\n","for epoch in range(n_epoch):\n","    train_losses = []\n","    train_elastic_losses = []\n","    train_total_losses = []\n","    val_losses = []\n","    val_elastic_losses = []\n","    val_total_losses = []\n","    faust_losses = []\n","    #metrics = []\n","    # Training single Epoch\n","    model.train()\n","    for i, data in enumerate(train_loader):\n","        shapeA, shapeB = data\n","        *shapeA, nameA, gtbasisA = shapeA\n","        *shapeB, nameB, gtbasisB = shapeB\n","        shapeA, shapeB = [x.to(device) for x in shapeA], [x.to(device) for x in shapeB]\n","        gtbasisA, gtbasisB = gtbasisA.to(device).to(torch.float32), gtbasisB.to(device).to(torch.float32)\n","        optim.zero_grad()\n","\n","        # Obtaining predicted basis\n","        #basisA, basisB = model(shapeA, shapeB)\n","        predA, predB = model(shapeA, shapeB)\n","        basisA, basisB = predA[:, :, :n_feat], predB[:, :, :n_feat]\n","        elasticA, elasticB = predA[:, :, n_feat:], predB[:, :, n_feat:]\n","\n","        # Computing optimal transformation\n","        pseudo_inv_A = torch.pinverse(basisA)\n","        C_opt = torch.matmul(pseudo_inv_A, basisB)\n","        opt_A = torch.matmul(basisA, C_opt)\n","\n","        # SoftMap\n","        dist_matrix = torch.cdist(opt_A, basisB)\n","        s_max = torch.nn.Softmax(dim=1)\n","        s_max_matrix = s_max(-dist_matrix)\n","\n","        # Basis Loss\n","        vertsB = shapeB[0] #get vertsB out\n","        eucl_loss = torch.sum(torch.square(torch.matmul(s_max_matrix, vertsB) - vertsB))\n","\n","        # Elastic Loss\n","        elastic_loss = l1_loss(elasticA, gtbasisA) + l1_loss(elasticB, gtbasisB)\n","        #metric = torch.mean(torch.square(s_max_matrix - torch.identity(s_max_matrix.shape[0]))) # measuring how well we are approximating the ground-truth correspondence\n","        # Back Prop\n","        total_loss = eucl_loss + 0.2 * elastic_loss\n","        total_loss.backward()\n","        #eucl_loss.backward()\n","        optim.step()\n","        train_losses.append(eucl_loss.detach().item())\n","        train_elastic_losses.append(elastic_loss.detach().item())\n","        train_total_losses.append(total_loss.detach().item())\n","        #metrics.append(metric.detach().item())\n","\n","    model.eval()\n","    with torch.no_grad():\n","      for i, data in enumerate(test_loader):\n","          shapeA, shapeB = data\n","          *shapeA, nameA, gtbasisA = shapeA\n","          *shapeB, nameB, gtbasisB = shapeB\n","          shapeA, shapeB = [x.to(device) for x in shapeA], [x.to(device) for x in shapeB]\n","          gtbasisA, gtbasisB = gtbasisA.to(device).to(torch.float32), gtbasisB.to(device).to(torch.float32)\n","\n","          #basisA, basisB = model(shapeA, shapeB)\n","          predA, predB = model(shapeA, shapeB)\n","          basisA, basisB = predA[:, :, :n_feat], predB[:, :, :n_feat]\n","          elasticA, elasticB = predA[:, :, n_feat:], predB[:, :, n_feat:]\n","\n","          pseudo_inv_A = torch.pinverse(basisA)\n","          C_opt = torch.matmul(pseudo_inv_A, basisB)\n","          opt_A = torch.matmul(basisA, C_opt)\n","          # SoftMap\n","          dist_matrix = torch.cdist(opt_A, basisB)\n","          s_max = torch.nn.Softmax(dim=1)\n","          s_max_matrix = s_max(-dist_matrix)\n","\n","          # Basis Loss\n","          vertsB = shapeB[0]\n","          val_eucl_loss = torch.sum(torch.square(torch.matmul(s_max_matrix, vertsB) - vertsB))\n","          val_elastic_loss = l1_loss(elasticA, gtbasisA) + l1_loss(elasticB, gtbasisB)\n","          val_total_loss = val_eucl_loss + 0.2 * val_elastic_loss\n","          val_losses.append(val_eucl_loss.detach().item())\n","          val_elastic_losses.append(val_elastic_loss.detach().item())\n","          val_total_losses.append(val_total_loss.detach().item())\n","\n","    ave_train_loss = sum(train_losses) / len(train_losses)\n","    ave_train_elastic_loss = sum(train_elastic_losses) / len(train_elastic_losses)\n","    ave_train_total_loss = sum(train_total_losses) / len(train_total_losses)\n","    ave_val_loss = sum(val_losses) / len(val_losses)\n","    ave_val_elastic_loss = sum(val_elastic_losses) / len(val_elastic_losses)\n","    ave_val_total_loss = sum(val_total_losses) / len(val_total_losses)\n","    #ave_metric = sum(metrics) / len(metrics)\n","    print()\n","    print(f\"training eucl loss for epoch{epoch}:\", ave_train_loss)\n","    print(f\"training elastic loss for epoch{epoch}:\", ave_train_elastic_loss)\n","    print(f\"training total loss for epoch{epoch}:\", ave_train_total_loss)\n","    print(f\"validation eucl loss for epoch{epoch}:\", ave_val_loss)\n","    print(f\"validation elastic loss for epoch{epoch}:\", ave_val_elastic_loss)\n","    print(f\"validation total loss for epoch{epoch}:\", ave_val_total_loss)\n","    #print(f\"training metric for epoch{epoch}:\", ave_metric)\n","    torch.save(model.state_dict(), os.path.join(model_save_dir, f\"train3_k_{n_feat}_epoch_{epoch}\"))\n","    epoch_train_loss.append(ave_train_loss)\n","    epoch_val_loss.append(ave_val_loss)\n","np.save(f\"/content/drive/MyDrive/P3DCV/losses/train/diffusionnet_k_{n_feat}.npy\", np.array(epoch_train_loss))\n","np.save(f\"/content/drive/MyDrive/P3DCV/losses/val/difffmap_k_{n_feat}.npy\", np.array(epoch_val_loss))\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CEPJ_LeoEbfE"},"source":["**visualization train and loss curves**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":949,"status":"ok","timestamp":1702570390115,"user":{"displayName":"Rui Xiao","userId":"00023545256536816003"},"user_tz":-60},"id":"ejrNFbunEhIh","outputId":"d27402c0-d64f-4dfe-e44c-70b97bebe18f"},"outputs":[{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABzvUlEQVR4nO3deVhU5dsH8O/MMOyboGyKiKYCikuuqKkpgkrmQqm9aKilZViZP1vMFcwsWyzLpcW0UistNTUVcS/FfUnFTJNEkyUzGBWBYea8f9AcGZiBAWbmwPj9XBeXznOeOee5Z4C5ebYjEwRBABEREZGNkkvdACIiIiJLYrJDRERENo3JDhEREdk0JjtERERk05jsEBERkU1jskNEREQ2jckOERER2TQmO0RERGTTmOwQERGRTWOyQ2QGY8aMQZMmTaRuRrX07t0bvXv3tvp1Db1mMpkMc+bMqfS5c+bMgUwmM2t79u7dC5lMhr1795r1vEQkPSY7ZNNkMplJX/yAM+7EiROQyWSYMWOG0ToXL16ETCbDlClTrNiy6lmyZAlWrlwpdTP09O7dG61bt5a6GSbRaDRYsWIFevfuDS8vLzg4OKBJkyYYO3Ysjh07JnXziAyyk7oBRJb09ddf6z3+6quvkJKSUq48NDS0Rtf57LPPoNVqa3SO2urBBx9ESEgIvvnmG7zxxhsG66xZswYAMGrUqBpd6+7du7Czs+yvpSVLlqB+/foYM2aMXnnPnj1x9+5d2NvbW/T6ddndu3cxbNgwbN++HT179sTrr78OLy8v/Pnnn1i7di2+/PJLZGRkoFGjRlI3lUgPkx2yaWU/fA8dOoSUlJRKP5Tz8/Ph7Oxs8nWUSmW12ldXxMXFYebMmTh06BC6du1a7vg333yDkJAQPPjggzW6jqOjY42eXxNyuVzS69cFL7/8MrZv346FCxdi8uTJesdmz56NhQsXmuU6Wq0WRUVFfD/IbDiMRfc93RDC8ePH0bNnTzg7O+P1118HAPz444+IiYlBQEAAHBwc0KxZM8ydOxcajUbvHGXnn/z555+QyWR499138emnn6JZs2ZwcHBAp06dcPTo0UrbdPPmTUydOhXh4eFwdXWFu7s7BgwYgNOnT+vV080zWbt2LebNm4dGjRrB0dERffv2xaVLl8qdV9cWJycndO7cGT///LNJr1FcXByAez04pR0/fhwXLlwQ65j6mhliaM7OL7/8gk6dOsHR0RHNmjXDJ598YvC5K1asQJ8+feDj4wMHBweEhYVh6dKlenWaNGmCc+fOYd++feIQpm6+krE5O+vWrUOHDh3g5OSE+vXrY9SoUfjrr7/06owZMwaurq7466+/MGTIELi6uqJBgwaYOnWqSXGbasmSJWjVqhUcHBwQEBCAhIQE5Obm6tW5ePEiYmNj4efnB0dHRzRq1AgjR45EXl6eWCclJQU9evSAp6cnXF1d0bJlS/F73phr167hk08+Qb9+/colOgCgUCgwdepUsVfH2Dw2Q/OtZDIZJk2ahNWrV4vxbd68GV5eXhg7dmy5c6hUKjg6OmLq1KliWWFhIWbPno0HHngADg4OCAwMxCuvvILCwsIK46L7A3t2iAD8888/GDBgAEaOHIlRo0bB19cXALBy5Uq4urpiypQpcHV1xe7duzFr1iyoVCq88847lZ53zZo1uHXrFp555hnIZDIsWLAAw4YNw+XLlyvsDbp8+TI2btyIxx9/HMHBwcjOzsYnn3yCXr16IS0tDQEBAXr133rrLcjlckydOhV5eXlYsGAB4uLicPjwYbHO8uXL8cwzz6Bbt26YPHkyLl++jEcffRReXl4IDAysMI7g4GB069YNa9euxcKFC6FQKPRiBID/+7//M8trVtqZM2cQFRWFBg0aYM6cOSguLsbs2bPF96e0pUuXolWrVnj00UdhZ2eHzZs347nnnoNWq0VCQgIA4IMPPsDzzz8PV1dXTJ8+HQAMnktn5cqVGDt2LDp16oT58+cjOzsbH374IQ4cOICTJ0/C09NTrKvRaBAdHY0uXbrg3Xffxc6dO/Hee++hWbNmmDhxYpXiNmTOnDlITExEZGQkJk6ciAsXLmDp0qU4evQoDhw4AKVSiaKiIkRHR6OwsBDPP/88/Pz88Ndff2HLli3Izc2Fh4cHzp07h0ceeQRt2rRBUlISHBwccOnSJRw4cKDC62/btg3FxcUYPXp0jWMxZPfu3Vi7di0mTZqE+vXro3nz5hg6dCjWr1+PTz75RG94cePGjSgsLMTIkSMBlPQEPfroo/jll18wYcIEhIaG4syZM1i4cCF+//13bNy40SJtpjpEILqPJCQkCGW/7Xv16iUAEJYtW1aufn5+frmyZ555RnB2dhYKCgrEsvj4eCEoKEh8nJ6eLgAQvL29hZs3b4rlP/74owBA2Lx5c4XtLCgoEDQajV5Zenq64ODgICQlJYlle/bsEQAIoaGhQmFhoVj+4YcfCgCEM2fOCIIgCEVFRYKPj4/Qrl07vXqffvqpAEDo1atXhe0RBEFYvHixAEBITk4WyzQajdCwYUMhIiJCLKvuayYIggBAmD17tvh4yJAhgqOjo3DlyhWxLC0tTVAoFOXeR0PXjY6OFpo2bapX1qpVK4Px6l7LPXv2CIJw7zVr3bq1cPfuXbHeli1bBADCrFmz9GIBoPfeCIIgtG/fXujQoUO5a5XVq1cvoVWrVkaP5+TkCPb29kJUVJTe98XHH38sABC++OILQRAE4eTJkwIAYd26dUbPtXDhQgGA8Pfff1fartJeeuklAYBw8uRJk+oben8FQRBmz55d7r0DIMjlcuHcuXN65cnJyQZ/XgYOHKj3vn799deCXC4Xfv75Z716y5YtEwAIBw4cMKnNZLs4jEUEwMHBwWB3uZOTk/j/W7du4caNG3jooYeQn5+P3377rdLzjhgxAvXq1RMfP/TQQwBKem4qa49cXvLjqdFo8M8//4jDDSdOnChXf+zYsXp/+Za9zrFjx5CTk4Nnn31Wr96YMWPg4eFRaRy6WJRKpd5Q1r59+/DXX3+JQ1hAzV8zHY1Gg+TkZAwZMgSNGzcWy0NDQxEdHV2ufunr5uXl4caNG+jVqxcuX76sN4RjKt1r9txzz+nNHYmJiUFISAh++umncs959tln9R4/9NBDlb7Xpti5cyeKioowefJk8fsCAMaPHw93d3exLbr3Mjk5Gfn5+QbPpeuN+vHHH6s0qV6lUgEA3NzcqhNCpXr16oWwsDC9sj59+qB+/fr47rvvxLJ///0XKSkpGDFihFi2bt06hIaGIiQkBDdu3BC/+vTpAwDYs2ePRdpMdQeTHSIADRs2NLgK59y5cxg6dCg8PDzg7u6OBg0aiJObTfkALf0hDUBMfP79998Kn6fVarFw4UI0b94cDg4OqF+/Pho0aIBff/3V4HUru86VK1cAAM2bN9erp1Qq0bRp00rjAABvb29ER0djw4YNKCgoAFAyhGVnZ4fhw4eL9Wr6mun8/fffuHv3brk2A0DLli3LlR04cACRkZFwcXGBp6cnGjRoIM5DqU6yo3vNDF0rJCREPK7j6OiIBg0a6JXVq1ev0ve6Jm2xt7dH06ZNxePBwcGYMmUKPv/8c9SvXx/R0dFYvHixXvwjRoxA9+7d8fTTT8PX1xcjR47E2rVrK0183N3dAZQksJYQHBxcrszOzg6xsbH48ccfxbk369evh1qt1kt2Ll68iHPnzqFBgwZ6Xy1atAAA5OTkWKTNVHcw2SGCfq+ATm5uLnr16oXTp08jKSkJmzdvRkpKCt5++20AMOmv4tJzW0oTBKHC57355puYMmUKevbsiVWrViE5ORkpKSlo1aqVwetW9zpVNWrUKKhUKmzZsgVFRUX44YcfxDk1gHles+r4448/0LdvX9y4cQPvv/8+fvrpJ6SkpOCll16y6HVLM/YeWNt7772HX3/9Fa+//jru3r2LF154Aa1atcK1a9cAlHyv79+/Hzt37sTo0aPx66+/YsSIEejXr1+Fk6lDQkIAlMyjMoWxTR+NXcPQzyAAjBw5Erdu3cK2bdsAAGvXrkVISAjatm0r1tFqtQgPD0dKSorBr+eee86kNpPt4gRlIiP27t2Lf/75B+vXr0fPnj3F8vT0dItf+/vvv8fDDz+M5cuX65Xn5uaifv36VT5fUFAQgJK/gHVd+wCgVquRnp6u98FRkUcffRRubm5Ys2YNlEol/v33X70hLHO+Zg0aNICTkxMuXrxY7tiFCxf0Hm/evBmFhYXYtGmTXi+XoeELU3de1r1mFy5c0HvNdGW649ZQui2le+KKioqQnp6OyMhIvfrh4eEIDw/HjBkzcPDgQXTv3h3Lli0T90mSy+Xo27cv+vbti/fffx9vvvkmpk+fjj179pQ7l86AAQOgUCiwatUqkyYp16tXr9xKMQDlesQq07NnT/j7++O7775Djx49sHv3bnFyuU6zZs1w+vRp9O3b1+w7a5NtYM8OkRG6v9RL944UFRVhyZIlVrl22V6ZdevWlVvybKqOHTuiQYMGWLZsGYqKisTylStXGvxAMsbJyQlDhw7F1q1bsXTpUri4uGDw4MF67QbM85opFApER0dj48aNyMjIEMvPnz+P5OTkcnXLXjcvLw8rVqwod14XFxeTYu7YsSN8fHywbNkyveXL27Ztw/nz5xETE1PVkKotMjIS9vb2WLRokV6My5cvR15entgWlUqF4uJiveeGh4dDLpeLMdy8ebPc+du1awcAFS7TDgwMxPjx47Fjxw589NFH5Y5rtVq89957Yg9Ss2bNkJeXh19//VWsk5mZiQ0bNpgYdQm5XI7HHnsMmzdvxtdff43i4mK9ISwAGD58OP766y989tln5Z5/9+5d3Llzp0rXJNvDnh0iI7p164Z69eohPj4eL7zwAmQyGb7++muzDw0Z8sgjjyApKQljx45Ft27dcObMGaxevdrk+TVlKZVKvPHGG3jmmWfQp08fjBgxAunp6VixYkWVzzlq1Ch89dVXSE5ORlxcHFxcXMRj5n7NEhMTsX37djz00EN47rnnUFxcjI8++gitWrXS+xCNioqCvb09Bg0ahGeeeQa3b9/GZ599Bh8fH2RmZuqds0OHDli6dCneeOMNPPDAA/Dx8SnXcwOUvGZvv/02xo4di169euGJJ54Ql543adJEHCIzl7///tvgDtXBwcGIi4vDtGnTkJiYiP79++PRRx/FhQsXsGTJEnTq1EmcE7V7925MmjQJjz/+OFq0aIHi4mJ8/fXXUCgUiI2NBQAkJSVh//79iImJQVBQEHJycrBkyRI0atQIPXr0qLCN7733Hv744w+88MILWL9+PR555BHUq1cPGRkZWLduHX777TdxOfjIkSPx6quvYujQoXjhhReQn5+PpUuXokWLFgYn2VdkxIgR+OijjzB79myEh4eX2/F89OjRWLt2LZ599lns2bMH3bt3h0ajwW+//Ya1a9ciOTkZHTt2rNI1ycZItg6MSALGlp4bW/Z74MABoWvXroKTk5MQEBAgvPLKK+JyWN0SZUEwvvT8nXfeKXdOlFlebUhBQYHwv//9T/D39xecnJyE7t27C6mpqUKvXr30lk3rlkuXXWqsu/6KFSv0ypcsWSIEBwcLDg4OQseOHYX9+/eXO2dliouLBX9/fwGAsHXr1nLHq/uaCYLh12bfvn1Chw4dBHt7e6Fp06bCsmXLDC5f3rRpk9CmTRvB0dFRaNKkifD2228LX3zxhQBASE9PF+tlZWUJMTExgpubm96y+7JLz3W+++47oX379oKDg4Pg5eUlxMXFCdeuXdOrEx8fL7i4uJR7LQy10xDd9geGvvr27SvW+/jjj4WQkBBBqVQKvr6+wsSJE4V///1XPH758mVh3LhxQrNmzQRHR0fBy8tLePjhh4WdO3eKdXbt2iUMHjxYCAgIEOzt7YWAgADhiSeeEH7//fdK2ykIJe//559/Ljz00EOCh4eHoFQqhaCgIGHs2LHllqXv2LFDaN26tWBvby+0bNlSWLVqldGl5wkJCUavqdVqhcDAQAGA8MYbbxisU1RUJLz99ttCq1atBAcHB6FevXpChw4dhMTERCEvL8+k2Mh2yQTBCn+mEhEREUmEc3aIiIjIpjHZISIiIpvGZIeIiIhsGpMdIiIismlMdoiIiMimMdkhIiIim8ZNBVGy8+f169fh5ubGrcaJiIjqCEEQcOvWLQQEBEAur6D/RspNflQqlfDiiy8KjRs3FhwdHYWIiAjhyJEj4nGtVivMnDlT8PPzExwdHYW+ffuW2/jqn3/+Ef7v//5PcHNzEzw8PIRx48YJt27dqlI7rl69anRDL37xi1/84he/+FW7v65evVrh57ykPTtPP/00zp49i6+//hoBAQFYtWoVIiMjkZaWhoYNG2LBggVYtGgRvvzySwQHB2PmzJmIjo5GWloaHB0dAQBxcXHIzMxESkoK1Go1xo4diwkTJmDNmjUmt8PNzQ0AcPXqVbi7u1c5DrVajR07diAqKgpKpbLKz68r7oc4GaNtYIy2gTHaBkvGqFKpEBgYKH6OGyNZsnP37l388MMP+PHHH8W7I8+ZMwebN2/G0qVLMXfuXHzwwQeYMWOGeKPBr776Cr6+vti4cSNGjhyJ8+fPY/v27Th69Kh435OPPvoIAwcOxLvvvouAgACT2qIbunJ3d692suPs7Ax3d3eb/WYF7o84GaNtYIy2gTHaBmvEWNkUFMmSneLiYmg0GrGHRsfJyQm//PIL0tPTkZWVhcjISPGYh4cHunTpgtTUVIwcORKpqanw9PTUu8FbZGQk5HI5Dh8+jKFDhxq8dmFhod7dfVUqFYCSN0StVlc5Ft1zqvPcuuR+iJMx2gbGaBsYo22wZIymnlOyZMfNzQ0RERGYO3cuQkND4evri2+++Qapqal44IEHkJWVBQDw9fXVe56vr694LCsrCz4+PnrH7ezs4OXlJdYxZP78+UhMTCxXvmPHDjg7O1c7ppSUlGo/ty65H+JkjLaBMdoGxmgbLBFjfn6+SfUknbPz9ddfY9y4cWjYsCEUCgUefPBBPPHEEzh+/LhFrztt2jRMmTJFfKwb84uKiqr2MFZKSgr69etns92QwP0RJ2O0DYzRNjBG22DJGHUjM5WRNNlp1qwZ9u3bhzt37kClUsHf3x8jRoxA06ZN4efnBwDIzs6Gv7+/+Jzs7Gy0a9cOAODn54ecnBy9cxYXF+PmzZvi8w1xcHCAg4NDuXKlUlmjN6Kmz68r7oc4GaNtYIzWo9FozD5ModFoYGdnB41GU/Gy4jqMMVZMqVRCoVBUeNwUtWKfHRcXF7i4uODff/9FcnIyFixYgODgYPj5+WHXrl1icqNSqXD48GFMnDgRABAREYHc3FwcP34cHTp0AADs3r0bWq0WXbp0kSocIqL7hiAIyMrKQm5urkXO7efnh6tXr9rsHmiMsXKenp7w8/Or0esjabKTnJwMQRDQsmVLXLp0CS+//DJCQkIwduxYyGQyTJ48GW+88QaaN28uLj0PCAjAkCFDAAChoaHo378/xo8fj2XLlkGtVmPSpEkYOXKkySuxiIio+nSJjo+PD5ydnc36ga3VanH79m24urrabK8HYzROEATk5+eLIzilR3mqStJkJy8vD9OmTcO1a9fg5eWF2NhYzJs3T+yWeuWVV3Dnzh1MmDABubm56NGjB7Zv3663gmv16tWYNGkS+vbtC7lcjtjYWCxatEiqkIiI7hsajUZMdLy9vc1+fq1Wi6KiIjg6Otp0IsAYjXNycgIA5OTkwMfHp8IhrYpImuwMHz4cw4cPN3pcJpMhKSkJSUlJRut4eXlVaQNBIiIyD90cnZqsYiWqjO77S61WVzvZsc00koiIrMZW55pQ7WCO769aMUHZFmm0Ao6k30TOrQL4uDmic7AXFHL+QiAiIrI2JjsWsP1sJhI3pyEzr0As8/dwxOxBYejfuvoTrIiIqPZq0qQJJk+ejMmTJ0vdFCqDw1hmtv1sJiauOqGX6ABAVl4BJq46ge1nMyVqGRFR7aXRCkj94x/8eOovpP7xDzRawWLXkslkFX7NmTOnWuc9evQoJkyYUKO29e7dm8mSBbBnx4w0WgGJm9Ng6EdUACADkLg5Df3C/DikRUT0H2O94TNjQtGtsfknP2dm3vuj87vvvsOsWbNw4cIFsczV1VX8vyAI4qZ4lWnQoIF5G0pmw54dMzp25d9yPTqlCQAy8wpwJP2m9RpFRFSLVdQbnrDmJHZd+Mfs1/Tz8xO/PDw8IJPJxMe//fYb3NzcsG3bNnTo0AEODg745Zdf8Mcff2Dw4MHw9fWFq6srOnXqhJ07d+qdt0mTJvjggw/ExzKZDJ9//jmGDh0KZ2dnNG/eHJs2bapR23/44Qe0atUKDg4OaNKkCd577z2940uWLEHz5s3h6OgIX19fPPbYY+Kx77//HuHh4XBycoK3tzciIyNx586dGrWnrmCyY0Y5tworrwQg55bxhIiIqC4TBAH5RcUmfd0qUGP2pnNGe8MB4O2dl3GrQG3S+QTBfENfr732Gt566y2cP38ebdq0we3btzFw4EDs2rULJ0+eRP/+/TFo0CBkZGRUeJ7ExEQMHz4cv/76KwYOHIi4uDjcvFm9P3iPHz+O4cOHY+TIkThz5gzmzJmDmTNnYuXKlQCAY8eO4YUXXkBSUhIuXLiA7du3o2fPngBKerOeeOIJjBs3DufPn8fevXsxbNgws75mtRmHsczIx638/bYM13OsvBIRUR10V61B2Kxks5xLAJBzqwhtk3ZWWhcA0pKi4Wxvno+1pKQk9OvXT3zs5eWFtm3bio/nzp2LDRs2YNOmTZg0aZLR84wZMwZPPPEEAODNN9/EokWLcOTIEfTv37/KbXr//ffRt29fzJw5EwDQokULpKWl4Z133sGYMWOQkZEBFxcXPPLII3Bzc0NQUBDat28PoCTZKS4uxrBhwxAUFAQACA8Pr3Ib6ir27JhRx6B68PdwhLHZODKUjEN3DvayZrOIiKiKOnbsqPf49u3bmDp1KkJDQ+Hp6QlXV1ecP3++0p6dNm3aiP93cXGBu7t7uRtYm+r8+fPo3r27Xln37t1x8eJFaDQa9OvXD0FBQWjatClGjx6N1atXIz8/HwDQtm1b9O3bF+Hh4Xj88cfx2Wef4d9//61WO+oi9uyYkUIuw+xBYZi46gRkgF7XrC4Bmj0ojJOTichmOSkVSEuKNqnukfSbGLPiaKX1vojvgK7N6pt0bXNxcXHRezx16lSkpKTg3XffxQMPPAAnJyc89thjKCoqqvA8Ze/KLZPJoNVqzdbO0tzc3HDixAns3bsXO3bswKxZszBnzhwcPXoUnp6eSElJwcGDB7Fjxw589NFHmD59Og4fPozg4GCLtKc2Yc+OmfVv7Y+lox6En4f+UJWfhyOWjnqQ++wQkU2TyWRwtrcz6euh5g0q7Q33dbPHQ80bmHQ+S+7kfODAAYwZMwZDhw5FeHg4/Pz88Oeff1rseoaEhobiwIED5drVokUL8TYKdnZ2iIyMxIIFC/Drr7/izz//xO7duwGUvDfdu3dHYmIiTp48CXt7e2zYsMGqMUiFPTsW0L+1P/qF+WHYkgM4fS0PE3s1w9ToluzRISIqxZTe8Fcim9aK353NmzfH+vXrMWjQIMhkMsycOdNiPTR///03Tp06pVfm7++P//3vf+jUqRPmzp2LESNGIDU1FR9//DGWLFkCANiyZQsuX76Mnj17ol69eti6dSu0Wi1atmyJw4cPY9euXYiKioKPjw8OHz6Mv//+G6GhoRaJobZhz46FKOQyNPhvInKQt3Ot+GElIqptKuoNX/x/7dG3pfnvpl4d77//PurVq4du3bph0KBBiI6OxoMPPmiRa61Zswbt27fX+/rss8/w4IMPYu3atfj222/RunVrzJo1C0lJSRgzZgwAwNPTE+vXr0efPn0QGhqKZcuW4ZtvvkGrVq3g7u6O/fv3Y+DAgWjRogVmzJiB9957DwMGDLBIDLUNe3YsyN6uJMFRayyT/RMR2QJdb3jZ+wnKIEClUln02mPGjBGTBaBkB2NDy7GbNGkiDgfpJCQk6D0uO6xl6Dy5ubkVtmfv3r0VHo+NjUVsbKzBYz169DD6/NDQUGzfvr3Cc9syJjsWpFSUdJwVae6PfQyIiKpLIZchopl+L47WgreMoPsLh7EsSJfssGeHiIhIOkx2LEhMdoqZ7BAREUmFyY4F2Ss4Z4eIiEhqTHYsiHN2iIiIpMdkx4KUdpyzQ0REJDUmOxbECcpERETSY7JjQZyzQ0REJD0mOxYkztkp5pwdIiIiqTDZsSAOYxER2a7evXtj8uTJ4uMmTZrggw8+qPA5MpkMGzdurPG1zXWe+wWTHQviBGUiIhNpNUD6z8CZ70v+1WosdqlBgwahf//+Bo/9/PPPkMlk+PXXX6t83qNHj2LChAk1bZ6eOXPmoF27duXKMzMzLX5fq5UrV8LT09Oi17AW3i7Cgjhnh4jIBGmbgO2vAqrr98rcA4Dot4CGvcx+uaeeegqxsbG4du0aGjVqpHdsxYoV6NixI9q0aVPl8zZo0MBcTayUn5+f1a5lC9izY0HcZ4eIqBJpm4C1T+onOgCgyoRsXTyUl7aZ/ZKPPPIIGjRogJUrV+qV3759G+vWrcNTTz2Ff/75B0888QQaNmwIZ2dnhIeH45tvvqnwvGWHsS5evIiePXvC0dERYWFhSElJKfec1157DR07doSrqyuaNm2KmTNnQq1WAyjpWUlMTMTp06chk8kgk8nENpcdxjpz5gz69OkDJycneHt7Y8KECbh9+7Z4fMyYMRgyZAjeffdd+Pv7w9vbGwkJCeK1qiMjIwODBw+Gq6sr3N3dMXz4cGRnZ4vHT58+jYcffhgeHh5o3LgxOnXqhGPHjgEArly5gkGDBqFevXpwcXFBq1atsHXr1mq3pTLs2bEg3i6CiO47ggCo802rq9UA214BYOgPQgGADE575wBhAwA7ZeXnUzoDMlml1ezs7PDkk09i5cqVmD59OmT/PWfdunXQaDR44okncPv2bXTo0AGvvvoq3N3d8dNPP2H06NFo1qwZOnfuXHloWi2GDRsGX19fHD58GHl5eXrze3Tc3NywePFiNG/eHOfOncP48ePh5uaGV155BSNGjMDZs2exfft27Ny5EwDg4eFR7hx37txBdHQ0IiIicPToUeTk5ODpp5/GpEmT9BK6PXv2wN/fH3v27MGlS5cwYsQItGvXDuPHj680HkPx6RKdffv2obi4GAkJCRgxYoR45/W4uDi0b98eixcvxt27d3Hp0iUolSXvY0JCAoqKirB//364uLggLS0Nrq6uVW6HqZjsWBAnKBPRfUedD7wZYJZTySBAdjsLWBBk2hNevw7Yu5hUddy4cXjnnXewb98+9O7dG0DJEFZsbCw8PDzg4eGBqVOnivWff/55JCcnY+3atSYlOzt37sRvv/2G5ORkBASUvB5vvvlmuXk206dPh0qlgru7O5o2bYqpU6fi22+/xSuvvAInJye4urrCzs6uwmGrNWvWoKCgAF999RVcXEri//jjjzFo0CC8/fbb8PX1BQDUq1cPH3/8MRQKBUJCQhATE4Ndu3ZVK9nZtWsXzpw5g/T0dAQGBgIAvvrqK7Rq1QpHjx5Fp06dkJGRgZdffhkhISFQqVRo37495PKSz8WMjAzExsYiPDwcANC0adMqt6EqOIxlQfZ2nLNDRFQbhYSEoFu3bvjiiy8AAJcuXcLPP/+Mp556CgCg0Wgwd+5chIeHw8vLC66urkhOTkZGRoZJ5z9//jwCAwPFRAcAIiIiytX77rvvEB0djYCAALi6umLGjBkmX6P0tdq2bSsmOgDQvXt3aLVaXLhwQSxr1aoVFAqF+Njf3x85OTlVulbpawYGBoqJDgCEhYXB09MT58+fBwBMmTIFTz/9NKKiorBw4UL88ccfYt0XXngBb7zxBrp3747Zs2dXa0J4VUia7Gg0GsycORPBwcFwcnJCs2bNMHfuXAjCvS5NQRAwa9Ys+Pv7w8nJCZGRkbh48aLeeW7evIm4uDi4u7vD09MTTz31lN5YpVTs5JyzQ0T3GaVzSQ+LKV9x35t0Su0Ta007n9K5Sk196qmn8MMPP+DWrVtYsWIFmjVrhl69SiZEv/POO/jwww/x6quvYs+ePTh16hSio6NRVFRU5ZfEmNTUVIwePRr9+vXDpk2bcPLkSUyfPt2s1yhNN4SkI5PJoNVa7o/xOXPm4Ny5cxg4cCB+/vlntG7dGhs2bAAAPP3007h8+TJGjx6NM2fOoGPHjvjoo48s1hZJk523334bS5cuxccff4zz58/j7bffxoIFC/QCXrBgARYtWoRly5bh8OHDcHFxQXR0NAoKCsQ6cXFxOHfuHFJSUrBlyxbs37/f7Mv/qoPDWER035HJSoaSTPlq1qdk1RUMz7MRIIPW1b+kninnM2G+TmnDhw+HXC7HmjVr8NVXX2HcuHHi/J0DBw5g8ODBGDVqFNq2bYumTZvi999/N/ncoaGhuHr1KjIzM8WyQ4cO6dU5ePAggoKCMHXqVHTs2BHNmzfHlStX9OrY29tDo6l4GX5oaChOnz6NO3fuiGUHDhyAXC5Hy5YtTW5zVejiu3r1qliWlpaG3NxchIWFiWUtWrTA5MmTsX79egwdOhQrVqwQjwUGBuLZZ5/F+vXr8b///Q+fffaZRdoKSJzsHDx4EIMHD0ZMTAyaNGmCxx57DFFRUThy5AiAkl6dDz74ADNmzMDgwYPRpk0bfPXVV7h+/bo4C/38+fPYvn07Pv/8c3Tp0gU9evTARx99hG+//RbXr1+v4OqWx2EsIqIKyBVA/7f/e1A2USl5fLf37JJ6FuDq6ooRI0Zg2rRpyMzMxJgxY8RjzZs3R0pKCg4ePIjz58/jmWee0VtpVJnIyEi0aNEC8fHxOH36NH7++WdMnz5dr07z5s2RkZGBH374AX/88QcWLVok9nzoNGnSBOnp6Th16hRu3LiBwsLCcteKi4uDo6Mj4uPjcfbsWezZswfPP/88Ro8eLc7XqS6NRoNTp07pfZ0/fx6RkZEIDw9HXFwcTpw4gSNHjuDJJ59Er1690LFjR9y9exeTJk3C3r17ceXKFRw6dAjHjh1DaGgoAGDy5MlITk5Geno6Tpw4gT179ojHLEHSCcrdunXDp59+it9//x0tWrTA6dOn8csvv+D9998HAKSnpyMrKwuRkZHiczw8PNClSxekpqZi5MiRSE1NhaenJzp27CjWiYyMhFwux+HDhzF06NBy1y0sLNT7hlGpVAAAtVpdrWV4uueUfa5MKElyioq1NVreV1sYi9OWMEbbwBit1wZBEKDVaqs/HBLyCPD4l5AlvwZZqeXngnsAtFFvQt2oNxz/u4YljB07FsuXL8eAAQPg5+cnXuf111/HH3/8gejoaDg7O2P8+PEYPHgw8vLy9NoilGlb6cc//PADxo8fj86dO4vL0gcOHCi+Xo888ghefPFFvPLKKygqKsLAgQMxY8YMJCYmiucYOnQofvjhBzz88MPIzc3F8uXLxaRMdx5HR0ds27YNL730Ejp16gRnZ2cMGzYM7733nngeQRAMtlV3HkO0Wi1u376N9u3b65U3a9YMv//+OzZs2IAXXngBPXv2hFwuR3R0NBYtWgStVguZTIYbN27gySefRHZ2Nry9vTFs2DDMnj0bWq1WXL117do1uLu7Izo6Gu+//77Btmi1WgiCALVarTfnCDD9+18mlJ4gY2VarRavv/46FixYAIVCAY1Gg3nz5mHatGkASnp+unfvjuvXr8Pf31983vDhwyGTyfDdd9/hzTffxJdffqk3CQsAfHx8kJiYiIkTJ5a77pw5c5CYmFiufM2aNXB2rtqYb0X+ugMs+NUObkoBb3S03G6gRERS0K0SCgwMhL29fc1OptXA7q8jkN3JgeDig+KGnS3Wo0N1S1FREa5evYqsrCwUFxfrHcvPz8f//d//IS8vD+7u7kbPIWnPztq1a7F69WqsWbMGrVq1wqlTpzB58mQEBAQgPj7eYtedNm0apkyZIj5WqVQIDAxEVFRUhS+WMWq1GikpKejXr5/eBLA//r6DBb8egNxOiYEDo83SdikZi9OWMEbbwBito6CgAFevXoWrqyscHR1rfkJP/d+TgiDg1q1bcHNzE+fS2BrGWLmCggI4OTmJGzSWphuZqYykyc7LL7+M1157DSNHjgQAhIeH48qVK5g/fz7i4+PFfQWys7P1enays7PFe4X4+fmVWzpXXFyMmzdvGt2XwMHBAQ4ODuXKlUpljX5plH2+s0PJXzpqjWBTv3Br+jrVBYzRNjBGy9JoNJDJZJDL5eL+KeakG9LQXcMWMcbKyeVyyGQyg9/rpn7vS/rK5ufnlwtcoVCIL0xwcDD8/Pywa9cu8bhKpcLhw4fF/QoiIiKQm5uL48ePi3V2794NrVaLLl26WCEK45ScoExERCQ5SXt2Bg0ahHnz5qFx48Zo1aoVTp48iffffx/jxo0DUJIFTp48GW+88QaaN2+O4OBgzJw5EwEBARgyZAiAkuVv/fv3x/jx47Fs2TKo1WpMmjQJI0eO1NvMSQr3lp6XTAyz1S5KIiKi2kzSZOejjz7CzJkz8dxzzyEnJwcBAQF45plnMGvWLLHOK6+8gjt37mDChAnIzc1Fjx49sH37dr1xu9WrV2PSpEno27cv5HI5YmNjsWjRIilC0qNLdoCShEe3FJ2IyJZIuM6F7gPm+P6SNNlxc3PDBx98oHeX2LJkMhmSkpKQlJRktI6XlxfWrFljgRbWjL1esqOFvZ1tjscS0f1JN18iPz8fTk5OEreGbFV+fsmNZWsyN403ArUgpeJeTw7n7RCRrVEoFPD09BQXiTg7O5t1uF6r1aKoqAgFBQU2PXmXMRomCALy8/ORk5MDT0/PcnvsVAWTHQtSyGWQyQBBAIqY7BCRDdKteq3uDSUrIggC7t69CycnJ5ud88gYK+fp6VnhXd9NwWTHgmQyGZQKeckOyrwZKBHZIJlMBn9/f/j4+Jh9N2e1Wo39+/ejZ8+eNruFAGOsmFKprFGPjg6THQuz1yU7xezZISLbpVAozPKhVPacxcXFcHR0tNlEgDFah20OENYiunk7nLNDREQkDSY7FqZbfs45O0RERNJgsmNhpTcWJCIiIutjsmNhur11OIxFREQkDSY7FibO2eEEZSIiIkkw2bEwcRhLy2EsIiIiKTDZsTAx2WHPDhERkSSY7FiYvYJzdoiIiKTEZMfClP/d6ZxLz4mIiKTBZMfCuPSciIhIWkx2LEzJYSwiIiJJMdmxMM7ZISIikhaTHQvT7bNTxNVYREREkmCyY2Gcs0NERCQtJjsWpuTtIoiIiCTFZMfCOGeHiIhIWkx2LEycs8Nkh4iISBJMdizs3u0iOGeHiIhICkx2LIz77BAREUmLyY6F2XOCMhERkaSY7FgY5+wQERFJi8mOhXGfHSIiImkx2bGwexOU2bNDREQkBSY7FsZ9doiIiKTFZMfClHacs0NERCQlJjsWxqXnRERE0pI02WnSpAlkMlm5r4SEBABAQUEBEhIS4O3tDVdXV8TGxiI7O1vvHBkZGYiJiYGzszN8fHzw8ssvo7i4WIpwDOIEZSIiImlJmuwcPXoUmZmZ4ldKSgoA4PHHHwcAvPTSS9i8eTPWrVuHffv24fr16xg2bJj4fI1Gg5iYGBQVFeHgwYP48ssvsXLlSsyaNUuSeAzhnB0iIiJpSZrsNGjQAH5+fuLXli1b0KxZM/Tq1Qt5eXlYvnw53n//ffTp0wcdOnTAihUrcPDgQRw6dAgAsGPHDqSlpWHVqlVo164dBgwYgLlz52Lx4sUoKiqSMjSRrmeniKuxiIiIJFFr5uwUFRVh1apVGDduHGQyGY4fPw61Wo3IyEixTkhICBo3bozU1FQAQGpqKsLDw+Hr6yvWiY6Ohkqlwrlz56wegyG6TQXZs0NERCQNO6kboLNx40bk5uZizJgxAICsrCzY29vD09NTr56vry+ysrLEOqUTHd1x3TFjCgsLUVhYKD5WqVQAALVaDbVaXeW2655j6LkylCQ5RcXaap27NqkoTlvBGG0DY7QNjNE2WDJGU89Za5Kd5cuXY8CAAQgICLD4tebPn4/ExMRy5Tt27ICzs3O1z6ubc1Ta1dsAYIdbd/KxdevWap+7NjEUp61hjLaBMdoGxmgbLBFjfn6+SfVqRbJz5coV7Ny5E+vXrxfL/Pz8UFRUhNzcXL3enezsbPj5+Yl1jhw5oncu3WotXR1Dpk2bhilTpoiPVSoVAgMDERUVBXd39yq3X61WIyUlBf369YNSqdQ7diHrFt49kwqF0gEDB/au8rlrk4ritBWM0TYwRtvAGG2DJWPUjcxUplYkOytWrICPjw9iYmLEsg4dOkCpVGLXrl2IjY0FAFy4cAEZGRmIiIgAAERERGDevHnIycmBj48PgJLM0d3dHWFhYUav5+DgAAcHh3LlSqWyRm+Eoec7OdoDKJmzYyvfyDV9neoCxmgbGKNtYIy2wRIxmno+yZMdrVaLFStWID4+HnZ295rj4eGBp556ClOmTIGXlxfc3d3x/PPPIyIiAl27dgUAREVFISwsDKNHj8aCBQuQlZWFGTNmICEhwWAyIwV77rNDREQkKcmTnZ07dyIjIwPjxo0rd2zhwoWQy+WIjY1FYWEhoqOjsWTJEvG4QqHAli1bMHHiRERERMDFxQXx8fFISkqyZggV4g7KRERE0pI82YmKioIgGO71cHR0xOLFi7F48WKjzw8KCqrVE391S8+LtQK0WgFyuUziFhEREd1fas0+O7ZKaXfvJVZr2btDRERkbUx2LEw3ZwfgvB0iIiIpMNmxMGXpZIe3jCAiIrI6JjsWppDLoJumw0nKRERE1sdkxwrEm4Ey2SEiIrI6JjtWwL12iIiIpMNkxwp0K7I4jEVERGR9THasQLfXThEnKBMREVkdkx0r4C7KRERE0mGyYwWcs0NERCQdJjtWwJ4dIiIi6TDZsQKl3X9zdpjsEBERWR2THSsQe3Y4QZmIiMjqmOxYgZJzdoiIiCTDZMcK7Dlnh4iISDJMdqxA3GeHyQ4REZHVMdmxAq7GIiIikg6THSsQbxfBCcpERERWx2THCripIBERkXSY7FgB5+wQERFJh8mOFejm7BSzZ4eIiMjqmOxYAScoExERSYfJjhXY2zHZISIikgqTHSvgnB0iIiLpMNmxAg5jERERSYfJjhXcuxEoJygTERFZG5MdK+C9sYiIiKTDZMcKOGeHiIhIOkx2rEDJ1VhERESSYbJjBUreLoKIiEgyTHasgHN2iIiIpCN5svPXX39h1KhR8Pb2hpOTE8LDw3Hs2DHxuCAImDVrFvz9/eHk5ITIyEhcvHhR7xw3b95EXFwc3N3d4enpiaeeegq3b9+2dihG6Xp2injXcyIiIquTNNn5999/0b17dyiVSmzbtg1paWl47733UK9ePbHOggULsGjRIixbtgyHDx+Gi4sLoqOjUVBQINaJi4vDuXPnkJKSgi1btmD//v2YMGGCFCEZpJugzJ4dIiIi67OT8uJvv/02AgMDsWLFCrEsODhY/L8gCPjggw8wY8YMDB48GADw1VdfwdfXFxs3bsTIkSNx/vx5bN++HUePHkXHjh0BAB999BEGDhyId999FwEBAdYNyoB7E5Q5Z4eIiMjaJE12Nm3ahOjoaDz++OPYt28fGjZsiOeeew7jx48HAKSnpyMrKwuRkZHiczw8PNClSxekpqZi5MiRSE1Nhaenp5joAEBkZCTkcjkOHz6MoUOHlrtuYWEhCgsLxccqlQoAoFaroVarqxyH7jnGnisXSnp0ioo11Tp/bVFZnLaAMdoGxmgbGKNtsGSMpp5T0mTn8uXLWLp0KaZMmYLXX38dR48exQsvvAB7e3vEx8cjKysLAODr66v3PF9fX/FYVlYWfHx89I7b2dnBy8tLrFPW/PnzkZiYWK58x44dcHZ2rnY8KSkpBsv/UAGAHf7Nu4WtW7dW+/y1hbE4bQljtA2M0TYwRttgiRjz8/NNqidpsqPVatGxY0e8+eabAID27dvj7NmzWLZsGeLj4y123WnTpmHKlCniY5VKhcDAQERFRcHd3b3K51Or1UhJSUG/fv2gVCrLHT91NReLzh2BvZMzBg58qEZtl1JlcdoCxmgbGKNtYIy2wZIx6kZmKiNpsuPv74+wsDC9stDQUPzwww8AAD8/PwBAdnY2/P39xTrZ2dlo166dWCcnJ0fvHMXFxbh586b4/LIcHBzg4OBQrlypVNbojTD2fCcH+5J2aQSb+Gau6etUFzBG28AYbQNjtA2WiNHU80m6Gqt79+64cOGCXtnvv/+OoKAgACWTlf38/LBr1y7xuEqlwuHDhxEREQEAiIiIQG5uLo4fPy7W2b17N7RaLbp06WKFKCpnzx2UiYiIJCNpz85LL72Ebt264c0338Tw4cNx5MgRfPrpp/j0008BADKZDJMnT8Ybb7yB5s2bIzg4GDNnzkRAQACGDBkCoKQnqH///hg/fjyWLVsGtVqNSZMmYeTIkbViJRYA2Ml5bywiIiKpSJrsdOrUCRs2bMC0adOQlJSE4OBgfPDBB4iLixPrvPLKK7hz5w4mTJiA3Nxc9OjRA9u3b4ejo6NYZ/Xq1Zg0aRL69u0LuVyO2NhYLFq0SIqQDFJyB2UiIiLJSJrsAMAjjzyCRx55xOhxmUyGpKQkJCUlGa3j5eWFNWvWWKJ5ZmHPfXaIiIgkI/ntIu4Hup4djVaARsuEh4iIyJqY7FiB7nYRAIeyiIiIrI3JjhXoenYAJjtERETWxmTHCvSTHQ5jERERWROTHStQyGVQyHnncyIiIikw2bES3bydomImO0RERNbEZMdKuNcOERGRNJjsWIm9gnvtEBERSYHJjpWwZ4eIiEgaTHasRGnH+2MRERFJgcmOlYg9O5ygTEREZFVMdqyEc3aIiIikwWTHSjhnh4iISBpMdqxE3GeHyQ4REZFVMdmxEvbsEBERSYPJjpXY2zHZISIikgKTHSu5txqLE5SJiIisicmOlXDODhERkTSY7FgJ5+wQERFJg8mOldgz2SEiIpIEkx0rUXJTQSIiIkkw2bES8d5YvF0EERGRVTHZsRLO2SEiIpIGkx0r4ZwdIiIiaTDZsRLO2SEiIpIGkx0r0SU73GeHiIjIupjsWIlugrKaE5SJiIisismOlXDODhERkTSY7FgJ5+wQERFJg8mOlXDpORERkTQkTXbmzJkDmUym9xUSEiIeLygoQEJCAry9veHq6orY2FhkZ2frnSMjIwMxMTFwdnaGj48PXn75ZRQXF1s7lErpbgTKZIeIiMi67KRuQKtWrbBz507xsZ3dvSa99NJL+Omnn7Bu3Tp4eHhg0qRJGDZsGA4cOAAA0Gg0iImJgZ+fHw4ePIjMzEw8+eSTUCqVePPNN60eS0Xs7TiMRUREJAXJkx07Ozv4+fmVK8/Ly8Py5cuxZs0a9OnTBwCwYsUKhIaG4tChQ+jatSt27NiBtLQ07Ny5E76+vmjXrh3mzp2LV199FXPmzIG9vb21wzGKS8+JiIikIXmyc/HiRQQEBMDR0RERERGYP38+GjdujOPHj0OtViMyMlKsGxISgsaNGyM1NRVdu3ZFamoqwsPD4evrK9aJjo7GxIkTce7cObRv397gNQsLC1FYWCg+VqlUAAC1Wg21Wl3lGHTPqei5cqEkySkq1lTrGrWBKXHWdYzRNjBG28AYbYMlYzT1nJImO126dMHKlSvRsmVLZGZmIjExEQ899BDOnj2LrKws2Nvbw9PTU+85vr6+yMrKAgBkZWXpJTq647pjxsyfPx+JiYnlynfs2AFnZ+dqx5OSkmL02Pl/ZQAUuHEzF1u3bq32NWqDiuK0FYzRNjBG28AYbYMlYszPzzepnqTJzoABA8T/t2nTBl26dEFQUBDWrl0LJycni1132rRpmDJlivhYpVIhMDAQUVFRcHd3r/L51Go1UlJS0K9fPyiVSoN16l3+B8t+Ow5nFzcMHNit2m2Xkilx1nWM0TYwRtvAGG2DJWPUjcxURvJhrNI8PT3RokULXLp0Cf369UNRURFyc3P1eneys7PFOT5+fn44cuSI3jl0q7UMzQPScXBwgIODQ7lypVJZozeiouc7OZTMHyrWCnX+G7qmr1NdwBhtA2O0DYzRNlgiRlPPV6v22bl9+zb++OMP+Pv7o0OHDlAqldi1a5d4/MKFC8jIyEBERAQAICIiAmfOnEFOTo5YJyUlBe7u7ggLC7N6+yvCCcpERETSqFayc/XqVVy7dk18fOTIEUyePBmffvpplc4zdepU7Nu3D3/++ScOHjyIoUOHQqFQ4IknnoCHhweeeuopTJkyBXv27MHx48cxduxYREREoGvXrgCAqKgohIWFYfTo0Th9+jSSk5MxY8YMJCQkGOy5kRL32SEiIpJGtZKd//u//8OePXsAlEwE7tevH44cOYLp06cjKSnJ5PNcu3YNTzzxBFq2bInhw4fD29sbhw4dQoMGDQAACxcuxCOPPILY2Fj07NkTfn5+WL9+vfh8hUKBLVu2QKFQICIiAqNGjcKTTz5ZpTZYiz1vF0FERCSJas3ZOXv2LDp37gwAWLt2LVq3bo0DBw5gx44dePbZZzFr1iyTzvPtt99WeNzR0RGLFy/G4sWLjdYJCgqqE6ubxNtF8K7nREREVlWtnh21Wi0OE+3cuROPPvoogJJ9cDIzM83XOhuitOOcHSIiIilUK9lp1aoVli1bhp9//hkpKSno378/AOD69evw9vY2awNtBefsEBERSaNayc7bb7+NTz75BL1798YTTzyBtm3bAgA2bdokDm+RPqW85KXWCoBGy3k7RERE1lKtOTu9e/fGjRs3oFKpUK9ePbF8woQJNdqB2JbphrGAkt4dhVwhYWuIiIjuH9Xq2bl79y4KCwvFROfKlSv44IMPcOHCBfj4+Ji1gbZCN4wFcN4OERGRNVUr2Rk8eDC++uorAEBubi66dOmC9957D0OGDMHSpUvN2kBboRvGArgii4iIyJqqleycOHECDz30EADg+++/h6+vL65cuYKvvvoKixYtMmsDbYVcLoOdXDdJmXN2iIiIrKVayU5+fj7c3NwAlNwpfNiwYZDL5ejatSuuXLli1gbaEnGvHQ5jERERWU21kp0HHngAGzduxNWrV5GcnIyoqCgAQE5OTrXuGn6/0M3b4ZwdIiIi66lWsjNr1ixMnToVTZo0QefOncUbc+7YsQPt27c3awNtib0de3aIiIisrVpLzx977DH06NEDmZmZ4h47ANC3b18MHTrUbI2zNfduGcE5O0RERNZSrWQHAPz8/ODn5yfe/bxRo0bcULASumSHw1hERETWU61hLK1Wi6SkJHh4eCAoKAhBQUHw9PTE3LlzodXyg9wY3jKCiIjI+qrVszN9+nQsX74cb731Frp37w4A+OWXXzBnzhwUFBRg3rx5Zm2kreBqLCIiIuurVrLz5Zdf4vPPPxfvdg4Abdq0QcOGDfHcc88x2TGCE5SJiIisr1rDWDdv3kRISEi58pCQENy8ebPGjbJV4pwdTlAmIiKymmolO23btsXHH39crvzjjz9GmzZtatwoW8U5O0RERNZXrWGsBQsWICYmBjt37hT32ElNTcXVq1exdetWszbQlnDODhERkfVVq2enV69e+P333zF06FDk5uYiNzcXw4YNw7lz5/D111+bu402w57JDhERkdVVe5+dgICAchORT58+jeXLl+PTTz+tccNs0b19djhnh4iIyFqq1bND1aPUrcYqZs8OERGRtTDZsSJOUCYiIrI+JjtWxDk7RERE1lelOTvDhg2r8Hhubm5N2mLzOGeHiIjI+qqU7Hh4eFR6/Mknn6xRg2wZl54TERFZX5WSnRUrVliqHfcFpd1/c3Y4QZmIiMhqOGfHijhnh4iIyPqY7FgR5+wQERFZH5MdK+KcHSIiIutjsmNF3GeHiIjI+mpNsvPWW29BJpNh8uTJYllBQQESEhLg7e0NV1dXxMbGIjs7W+95GRkZiImJgbOzM3x8fPDyyy+juLjYyq03jb0de3aIiIisrVYkO0ePHsUnn3yCNm3a6JW/9NJL2Lx5M9atW4d9+/bh+vXrenv9aDQaxMTEoKioCAcPHsSXX36JlStXYtasWdYOwSTinJ1iztkhIiKyFsmTndu3byMuLg6fffYZ6tWrJ5bn5eVh+fLleP/999GnTx906NABK1aswMGDB3Ho0CEAwI4dO5CWloZVq1ahXbt2GDBgAObOnYvFixejqKhIqpCM4pwdIiIi65M82UlISEBMTAwiIyP1yo8fPw61Wq1XHhISgsaNGyM1NRUAkJqaivDwcPj6+op1oqOjoVKpcO7cOesEUAWcs0NERGR9VdpU0Ny+/fZbnDhxAkePHi13LCsrC/b29vD09NQr9/X1RVZWllindKKjO647ZkxhYSEKCwvFxyqVCgCgVquhVqurHIfuOZU9V46S4auiYk21riM1U+OsyxijbWCMtoEx2gZLxmjqOSVLdq5evYoXX3wRKSkpcHR0tOq158+fj8TExHLlO3bsgLOzc7XPm5KSUuHxszdlABT4+59/sXXr1mpfR2qVxWkLGKNtYIy2gTHaBkvEmJ+fb1I9yZKd48ePIycnBw8++KBYptFosH//fnz88cdITk5GUVERcnNz9Xp3srOz4efnBwDw8/PDkSNH9M6rW62lq2PItGnTMGXKFPGxSqVCYGAgoqKi4O7uXuVY1Go1UlJS0K9fPyiVSqP13C7ewGcXTsDZ1R0DB0ZU+TpSMzXOuowx2gbGaBsYo22wZIy6kZnKSJbs9O3bF2fOnNErGzt2LEJCQvDqq68iMDAQSqUSu3btQmxsLADgwoULyMjIQERESaIQERGBefPmIScnBz4+PgBKMkd3d3eEhYUZvbaDgwMcHBzKlSuVyhq9EZU939Gh5FixVqjT39Q1fZ3qAsZoGxijbWCMtsESMZp6PsmSHTc3N7Ru3VqvzMXFBd7e3mL5U089hSlTpsDLywvu7u54/vnnERERga5duwIAoqKiEBYWhtGjR2PBggXIysrCjBkzkJCQYDCZkRrvjUVERGR9kk5QrszChQshl8sRGxuLwsJCREdHY8mSJeJxhUKBLVu2YOLEiYiIiICLiwvi4+ORlJQkYauNu7f0nPvsEBERWUutSnb27t2r99jR0RGLFy/G4sWLjT4nKCiozkz25T47RERE1if5Pjv3E3s77rNDRERkbUx2rIjDWERERNbHZMeKxHtjsWeHiIjIapjsWFHpOTuCwN4dIiIia2CyY0W6peeCAGi0THaIiIisgcmOFSn/m6AMcN4OERGRtTDZsSI7+b2Xm/N2iIiIrIPJjhUpFaV7dpjsEBERWQOTHSuSyWRiwsNkh4iIyDqY7FiZuCKrmHN2iIiIrIHJjpVxrx0iIiLrYrJjZbw/FhERkXUx2bEye87ZISIisiomO1amtGPPDhERkTUx2bEycc4OJygTERFZBZMdK+OcHSIiIutismNlnLNDRERkXUx2rIw9O0RERNbFZMfK7u2zwzk7RERE1sBkx8rE1VjF7NkhIiKyBiY7VsY5O0RERNbFZMfKOGeHiIjIupjsWBnn7BAREVkXkx0rY88OERGRdTHZsTJ7u//m7HCCMhERkVUw2bEy9uwQERFZF5MdK+OcHSIiIutismNl7NkhIiKyLiY7VsZ9doiIiKyLyY6VsWeHiIjIupjsWJnudhFFxZyzQ0REZA2SJjtLly5FmzZt4O7uDnd3d0RERGDbtm3i8YKCAiQkJMDb2xuurq6IjY1Fdna23jkyMjIQExMDZ2dn+Pj44OWXX0ZxcbG1QzEZe3aIiIisS9Jkp1GjRnjrrbdw/PhxHDt2DH369MHgwYNx7tw5AMBLL72EzZs3Y926ddi3bx+uX7+OYcOGic/XaDSIiYlBUVERDh48iC+//BIrV67ErFmzpAqpUpyzQ0REZF12Ul580KBBeo/nzZuHpUuX4tChQ2jUqBGWL1+ONWvWoE+fPgCAFStWIDQ0FIcOHULXrl2xY8cOpKWlYefOnfD19UW7du0wd+5cvPrqq5gzZw7s7e2lCKtC7NkhIiKyLkmTndI0Gg3WrVuHO3fuICIiAsePH4darUZkZKRYJyQkBI0bN0Zqaiq6du2K1NRUhIeHw9fXV6wTHR2NiRMn4ty5c2jfvr3BaxUWFqKwsFB8rFKpAABqtRpqtbrKbdc9x5TnylEyV6dQranWtaRUlTjrKsZoGxijbWCMtsGSMZp6TsmTnTNnziAiIgIFBQVwdXXFhg0bEBYWhlOnTsHe3h6enp569X19fZGVlQUAyMrK0kt0dMd1x4yZP38+EhMTy5Xv2LEDzs7O1Y4lJSWl0jrnbsgAKJCV8ze2bt1a7WtJyZQ46zrGaBsYo21gjLbBEjHm5+ebVE/yZKdly5Y4deoU8vLy8P333yM+Ph779u2z6DWnTZuGKVOmiI9VKhUCAwMRFRUFd3f3Kp9PrVYjJSUF/fr1g1KprLCu4lw2vrx4Gu6eXhg4sHOVryWlqsRZVzFG28AYbQNjtA2WjFE3MlMZyZMde3t7PPDAAwCADh064OjRo/jwww8xYsQIFBUVITc3V693Jzs7G35+fgAAPz8/HDlyRO98utVaujqGODg4wMHBoVy5Uqms0RthyvOdHEqOF2uFOvuNXdPXqS5gjLaBMdoGxmgbLBGjqeerdfvsaLVaFBYWokOHDlAqldi1a5d47MKFC8jIyEBERAQAICIiAmfOnEFOTo5YJyUlBe7u7ggLC7N6203Be2MRERFZl6Q9O9OmTcOAAQPQuHFj3Lp1C2vWrMHevXuRnJwMDw8PPPXUU5gyZQq8vLzg7u6O559/HhEREejatSsAICoqCmFhYRg9ejQWLFiArKwszJgxAwkJCQZ7bmoDhaxk6fnNO4VI/eMfdA72gkIuk7hVREREtkvSZCcnJwdPPvkkMjMz4eHhgTZt2iA5ORn9+vUDACxcuBByuRyxsbEoLCxEdHQ0lixZIj5foVBgy5YtmDhxIiIiIuDi4oL4+HgkJSVJFVKFtp/NxPQNZwEA2apCPPHZIfh7OGL2oDD0b+0vceuIiIhsk6TJzvLlyys87ujoiMWLF2Px4sVG6wQFBdWJVU3bz2Zi4qoTKDt4lZVXgImrTmDpqAeZ8BAREVlArZuzY4s0WgGJm9PKJToAxLLEzWnQaDmPh4iIyNyY7FjBkfSbyMwrMHpcAJCZV4Aj6Tet1ygiIqL7BJMdK8i5ZTzRqU49IiIiMh2THSvwcXM0az0iIiIyHZMdK+gc7AV/D0cYW2AuA+Dv4YjOwV7WbBYREdF9gcmOFSjkMsweVLLJYdmER/d49qAw7rdDRERkAUx2rKR/a38sHfUg/Dz0h6r8PBy57JyIiMiCJL831v2kf2t/9AvzQ+ofNzB25VGoNQK+GNMJof5Vv/koERERmYY9O1amkMvQo3kDdAwqmZ9zMiNX2gYRERHZOCY7EunYpB4A4PiVfyVuCRERkW1jsiORB4N0yQ43EiQiIrIkJjsSebBxSbLz5z/5+PtWocStISIisl1MdiTi4aREC19XAMCJDA5lERERWQqTHQl1+G+SMuftEBERWQ6THQl1DOIkZSIiIktjsiOhDv8lO2eu5aFArZG4NURERLaJyY6EgrydUd/VHkUaLc5dz5O6OURERDaJyY6EZDKZuCrr2J8cyiIiIrIEJjsS020ueIzzdoiIiCyCyY7EdCuyTlz5F4IgSNwaIiIi28NkR2KtG7rD3k6Of+4U4c9/8qVuDhERkc1hsmMpWg2Q/jNw5vuSf7WGV1s52CnQpqEHAC5BJyIisgQ7qRtgk9I2AdtfBVTX75W5BwD93wbCHi1XvUNQPRy78i+2nrkOpUIGHzdHdA72gkIus2KjiYiIbBOTHXNL2wSsfRJAmfk3qsyS8uFflUt4ZP/lNLt/+xu7f/sbAODv4YjZg8LQv7W/FRpNRERkuziMZU5aTUmPTtlEB7hXtv01vSGt7WczsWzf5XK1s/IKMHHVCWw/m2mZthIREd0nmOyYkexqqv7QVTkCoPoLuHIQAKDRCkjcnGasJgAgcXMaNFqu0iIiIqouJjvmdDu7SvWOpN9EZl6B0WoCgMy8AhxJv2mGxhEREd2fmOyYk6tvlerl3DKe6JRmaj0iIiIqj8mOGQmBESWrrmBsFZUMcG8IBHUDAPi4OZp0XlPrERERUXlMdsxJrihZXg6gfMLz3+P+b5XUA9A52Av+Ho4VpUbw9yhZhk5ERETVI2myM3/+fHTq1Alubm7w8fHBkCFDcOHCBb06BQUFSEhIgLe3N1xdXREbG4vsbP25MRkZGYiJiYGzszN8fHzw8ssvo7i42Jqh3BP2aMnycvcyS8advcotO1fIZZg9KAyA8b6g2YPCuN8OERFRDUia7Ozbtw8JCQk4dOgQUlJSoFarERUVhTt37oh1XnrpJWzevBnr1q3Dvn37cP36dQwbNkw8rtFoEBMTg6KiIhw8eBBffvklVq5ciVmzZkkRUomwR4HJZ4H4LUDjkiErdBhrcEPB/q39sXTUg/Dz0B+qUshlWPx/D3KfHSIiohqSdFPB7du36z1euXIlfHx8cPz4cfTs2RN5eXlYvnw51qxZgz59+gAAVqxYgdDQUBw6dAhdu3bFjh07kJaWhp07d8LX1xft2rXD3Llz8eqrr2LOnDmwt7eXIrSSoargh4AbjwEZB4G/jhmt2r+1P/qF+eFI+k1c/TcfiZvO4U6RBsW8MSgREVGN1aodlPPy8gAAXl4lc1SOHz8OtVqNyMhIsU5ISAgaN26M1NRUdO3aFampqQgPD4ev772VUNHR0Zg4cSLOnTuH9u3bl7tOYWEhCgsLxccqlQoAoFaroVarq9xu3XMMPtevPZQAhGvHUFxYIM7XMaRjY3d0bOyOazfvYNHuP/DRrt8RHVIf8loyjFVhnDaCMdoGxmgbGKNtsGSMpp6z1iQ7Wq0WkydPRvfu3dG6dWsAQFZWFuzt7eHp6alX19fXF1lZWWKd0omO7rjumCHz589HYmJiufIdO3bA2dm52jGkpKSUK5MJGgyU28Ou6DZ+3rAct5waVXoe/2LAUaHAxZw7mPzZdjRwAtyVQDN3AbUh7zEUp61hjLaBMdoGxmgbLBFjfn6+SfVqTbKTkJCAs2fP4pdffrH4taZNm4YpU6aIj1UqFQIDAxEVFQV3d/cqn0+tViMlJQX9+vWDUqksd1x+8zMg4yB6NnOG0G6gSefce+cUktNysO3avZ4gP3cHzBgYguhWJu7nY2aVxWkLGKNtYIy2gTHaBkvGqBuZqUytSHYmTZqELVu2YP/+/WjU6F7Ph5+fH4qKipCbm6vXu5OdnQ0/Pz+xzpEjR/TOp1utpatTloODAxwcHMqVK5XKGr0RRp8f2BnIOAi7zBNAp7GVnmf72UzsSMspV56tKsTz357G0lHSTlyu6etUFzBG28AYbQNjtA2WiNHU80m6GksQBEyaNAkbNmzA7t27ERwcrHe8Q4cOUCqV2LVrl1h24cIFZGRkICIiAgAQERGBM2fOICfnXnKQkpICd3d3hIWFWSeQygR2Lvn3mvFJyjq6+2VVcCtR3i+LiIioCiTt2UlISMCaNWvw448/ws3NTZxj4+HhAScnJ3h4eOCpp57ClClT4OXlBXd3dzz//POIiIhA165dAQBRUVEICwvD6NGjsWDBAmRlZWHGjBlISEgw2HsjiYYdS/7NOQ8UqABH40NlVblfVkQzbzM3lIiIyPZI2rOzdOlS5OXloXfv3vD39xe/vvvuO7HOwoUL8cgjjyA2NhY9e/aEn58f1q9fLx5XKBTYsmULFAoFIiIiMGrUKDz55JNISkqSIiTD3HwBz8YABOCv4xVW5f2yiIiIzEvSnh3BhH1kHB0dsXjxYixevNhonaCgIGzdutWcTTO/Rp2A3IySoaxmDxutxvtlERERmRfvjWUtjTqV/HvtaIXVKrtfFsD7ZREREVUFkx1rKZ3sVNCjZcr9sh5p448j6Tfx46m/kPrHP5ysTEREVIFasfT8vuAXDijsgbs3gZuXAe9mRqvq7peVuDlNb7Kyi4MCdwo1+PzndHz2c7pY7u/hiNmDwngfLSIiIgOY7FiLnQPg37akZ+fasQqTHUD/flk5twrg4+aIv28V4IVvT5Vblp6VV4CJq05Ivv8OERFRbcRhLGtqpNtvp+J5OzoKuQwRzbwxuF1DdA72wvxtvxmsx/13iIiIjGOyY02N/ttvx8Rkp7Sq7L9DRERE93AYy5p0k5SzfgVOri7ZeyeoW4V3QtcxdV+dA5f+Foe9Ogd7QVEb7hxKREQkISY71nT9BCCTA4IW+PG5kjL3AKD/20DYoxU+1dR9dT7e84f4f05cJiIi4jCW9aRtAtbGlyQ6pakygbVPlhyvgCn775Slm7i8/Wxm1dtLRERkI5jsWINWA2x/Fajo9p7bXyupZ4Qp++8YOTMnLhMR0X2NyY41XDkIqK5XUEEAVH+V1KuAbv8dPw/TbxWhm7i8MOV3bkBIRET3Jc7ZsYbb2WarV3b/nYvZt/HxnkuVPu/jPZfw8Z5LnMdDRET3HfbsWIOrr1nrld5/p/sD9avUFM7jISKi+w2THWsI6lay6srobBsZ4N6wpF4VVXXiMufxEBHR/YbJjjXIFSXLywEYTngEoP9bJu23U1Z1Jy5n5hVg5YF03kyUiIhsHufsWEvYo8Dwr0pWZZWdrGznBAQ8CKT/XDJvx9XX5M0GAeM3Dq3M3J/Oi//nXB4iIrJVTHasKexRICSmZNXV7WzApQGwMxG4fhz4uANQXCpRMXGzQZ3SE5cPXPpbb3NBU/BmokREZKuY7FibXAEEP3TvcethJclOcZkeGd1mg8O/Mjnh0U1c7hzshR9O/IWsvAKDO/sYIqBkGGzOpnNwc1Tixu1C3nKCiIhsApMdKWk1wKHFRg7+l35sf62kN6gK83l083gmrjoBGQxvZWjsilmqQsR9flgs4/AWERFVSqu5N2pRxakY1sAJylIy02aDhlRnA0JDdMNbW3+9jsPpN3H8hgyH029yQjMREZVI2wR80Br48hHgh6dK/v2gdaW3QbIm9uxIydTNBs//9w1TxUy57AaEN24V6k1KNoUupZn0zUmU5DcKfHXxGHt8iIhqA6l7VNI2lUy5KDuGoJuK8dhKyBw90PBmKmRX3IGmPSXp8WGyIyVTNxs88mnJVxUnLQP35vEAgEYr4PNf0qs0l0enbEdOVl4Bnl11Ai9FNkeT+i6c30NE9xdjSYahcsBoXdmVX8onAqYmMGmbyq/wrexzoortq7D8ViawfRoqvO/jD2NhJ2jREQCuLK3W55g5MNmRkm6zQVUmTJpZUypThot3lTP56s7lMUT33IU7L4pl7O0hovuCsSSj9WPA2e/1y53qAZABd28arGunuq6fCBg6h3sAEDVf//d+/j/AujGoqEel3OfEbz+Vb3cl7TMpxooIWsPtq8LiG3NgsiMl3WaDa58ETEo/7mXKet9Auky59LJ2I0lQdffkMYVufs/i/2uPei4OyLlVwB4fIpJOVYZ4TO2pMZpkXAcOLip/3rv/li8zVrei8u/j9ctk8vJtAGD0c8KpnuG2mKN9VVL9xTc1wWRHahVtNmiMwUx5NODkVT47L/vXQFC3cnN56rs44H/rTiNbVfXhLb1m/ffvvfk9JdjjQ1RKVYYRLHluMw3DWPLcBod4TI3bUC+GsT8M8/8BkqeZ1othNMmwsrKfA5UdN5TUSKbU4pvSW7FYEJOd2qD0ZoPnN5XMz6mS/37wSic6gOG/Bv77YVeEPSrO5QGAOY+aZ3gLMDy/hz0+RDA8/GFsGKGi3lpDiYClhijMcQ5zDfGYmqgY68Uw9oehIcZ6MSpLMsh0pi7SMQOZIAi1IEWVlkqlgoeHB/Ly8uDu7l7l56vVamzduhUDBw6EUqmsWWPSfy5Ztmcx/yUXBsZzt6fllBveksvKJy/VVfZc/h6OmBkTWqsSILO+l7VUnYuxGqtNahyjJXo9jA1/GPTfnx2GemuNJQ216i93SzDymlDdFb+lxj07pn5+s2entqnqpOUqMz7vp3//t9Hv5YH47XAy7v77F5zqNcQV17ZI+OY05NCik/w3+CAXOfDEEW0IAKBzmTJtBVs3lU2aMvMK8Nyak3pluiGv0sNstSEJui9VdYjCEqq52sTkFS6A6cMfNe31qNLwRwW9tabOC7E5Rl4Tqp1k8gp6wWQlPye6n0ErYLJT21R50nI1GZn3o3DyQqtSv0xauQdgV5sBcPl9I3zxj1h+U3AFAHjJbotl1wUvJKqfRIq2o8EkSA5tuXJAP2E6mheCZ1edgJeTHC0Kz4rlV13bYuaj4ffHvB8Lz6UolwgYOkdVPvArGnKpRvvE8n/+APbOR3VWm5i0wsVQomJ0+MMMk085/EG2zrk+0H8+4OZfqicT0P8Z/u+P1v5vWXW/HQ5joZYNY+kY+ou2wkzZsnT3zhIf//ddIytVqOu5yYVruSRoU3E3PGp3EAGyex8sxhImQ3WvC15IUj+JR0c8jaDbv4o9TyFdoqGwM5KzV2PyZPHl/Tj1czLaPRQNu+psflXT1R+W6lUwxwe+UUaGFyy9pLXsz8N9MZRDVEbZnwNJPif++yAou5zcYM9sw5JEx0zLzk39/JY02dm/fz/eeecdHD9+HJmZmdiwYQOGDBkiHhcEAbNnz8Znn32G3NxcdO/eHUuXLkXz5s3FOjdv3sTzzz+PzZs3Qy6XIzY2Fh9++CFcXV1NbketTHaACsb8gVqxGsAAY0mQ7mHp8qrU1SVSeXBFvVLJUTa8cT1iNtr0jdMbfgvxKIJix+s1mzxpZDWb0YTJWKJi6BzGJpPyw5qobiibVLg3BFrHGviDwqvkX72k30hdY+WGG1DyT9kezgp7VAz9UWKG9lWUwJjjj8gK1IlkZ9u2bThw4AA6dOiAYcOGlUt23n77bcyfPx9ffvklgoODMXPmTJw5cwZpaWlwdCy559OAAQOQmZmJTz75BGq1GmPHjkWnTp2wZs0ak9tRa5MdQwyu5tB981pw2KuGBEE/ealO3Yp6k1QyV3jiXhKkexX0eqPKPK4Wc0wQZVJDVIcZX+RRneFmg4mAoT90yy2NryDBqKhHxdzDzSbM27PkZ2SdSHZKk8lkesmOIAgICAjA//73P0ydOhUAkJeXB19fX6xcuRIjR47E+fPnERYWhqNHj6Jjx44AgO3bt2PgwIG4du0aAgICTLp2nUp2ANN7Fe4ThpIgowkTzJDwEFEtV0Evhql/GFanF6MaTP78qOrCAKnvmVVKbUh2au0E5fT0dGRlZSEyMlIs8/DwQJcuXZCamoqRI0ciNTUVnp6eYqIDAJGRkZDL5Th8+DCGDh0qRdMtT64ov1yv9F49Ff01IOG8H0sxlNQY60ViokOSKzfXyMAwQpV7ay04RGGuYY6anrtKiUqA8V4Mg8PNDYGoNw331ETOqR1Jg6Hf++asb+NqbbKTlZUFAPD11b9Zpq+vr3gsKysLPj4+esft7Ozg5eUl1jGksLAQhYWF4mOVSgWgJPtUq9VVbqvuOdV5rtk16qr/+IH+kF1NLZUA3YRi/VMAAFmpXxiGhn1KH2OSQEDd/V6oSruNDYGignLT6pY80gz9HHD2En8mhcCIkrqlfk6FwAjIft8GxY7XIbt170NZcG8IbdhQyM+tL1MeAE2/eRBaDCh3HkPnhlwB9Jpuerk5zlGNc2vSf8HZ1J1oHREJRXAPo6+JJnJu+ddUrgA0Wv3fiRot0HwA0CzK8DVL02hLvoDy59CY7w/GWvX5YSGWjNHUc9baZMeS5s+fj8TExHLlO3bsgLOzc7XPm5KSUpNmWZgTABUAO/gHT0L4tdVwUt/7a6pI4Qp7ze3yq65K/WvqL/maJkxVmd9zv6jqh3WN34P//q3u94I521e2XAsZZGLqUL5u2bZU53u4SOEKB829OWB3lV74q14XNPr3cLmfGwAm1b2rrIezjeKQmW6Hkp/F/34mzyWXakHpMjnQ7E14374AR3UuCpSe+Me1JVAoB5p1LF9+WQ5cTjZwHkPnRjXLzXGOKp7bKwJ/XbgDXKjgNUmXw/hrWpGq1rec2v35YR6WiDE/P9+kerU22fHz8wMAZGdnw9//3t4q2dnZaNeunVgnJydH73nFxcW4efOm+HxDpk2bhilTpoiPVSoVAgMDERUVVe05OykpKejXr1/d2JEWAwHtDBSX+stGHhgBzX9/NeGWfveu7i9JvXInLwCC/kTb/7qZhf8+jHSq/GEjM22pe3VUNPm5NiRY5vqwrlnSqhsSKTORuqLvhQre95q1r6Qtmp6vQvBqqtc7WVJXKFe3Su0u+z3s3hCafvMgbzFA7+dDGRiBJroJpWV+bgCYVFcZGIH2cgXao6oM76iuVkfXsd87VWf8d6sld5m3rrr3+VF1loxRNzJTmVqb7AQHB8PPzw+7du0SkxuVSoXDhw9j4sSJAICIiAjk5ubi+PHj6NChAwBg9+7d0Gq16NKli9FzOzg4wMHBoVy5Uqms0RtR0+dblxJ44GH9ovChQKtH9canZUHdoJArgKik8qsGgHJ1DY2Hy4yMwcsMjNfr6gpl6hY5eMK+MBdaoeS2EzoVJUFlExjdsnZTy6uaGFV1ojRQtsfiv8flbhHQELIqvn7l6lbpPTA836H094JJ77s52vdfWxRlJ4PaKQ18n91rd9nvVaPtBsqV2emGM8r+fAAw+HNT1bpmVrd+71QPY7QNlojR1PNJmuzcvn0bly5dEh+np6fj1KlT8PLyQuPGjTF58mS88cYbaN68ubj0PCAgQFyxFRoaiv79+2P8+PFYtmwZ1Go1Jk2ahJEjR5q8EovKMDapTa6AENQDf51ToW1Qj3vj26ZMlK5ooh9gsK6sTF2HoG44mbIKAamJejs558pc4SncLpcEld6vRycL3thUHFGyYSFuVloOVC1hAv7bULHUEnhj5xDrltozKEvwRqJ6NI7KuqJFUandowvaYmZAOPr1ma2/l1CXaAAoV6aws4PGQF2FnR0QOafSpFVvAqaR7wWT33dj5zY26dPUyaAVfZ8Bhr9XjX1vcxInkc2TNNk5duwYHn743l8+uqGl+Ph4rFy5Eq+88gru3LmDCRMmIDc3Fz169MD27dvFPXYAYPXq1Zg0aRL69u0rbiq4aJGBrdrJeipImEz+sDFQt310PDR943CuzIf4qV2ryyVBWfBGkjoOuXAvd9uKBZqRBm9nUba8Hm5hpvJrkxKjLJQkKmVvlWHsHIbqivcWu6vFIYSJ9WUqNZ5ddQKezkrk5gNAQwCA567dAKBX5r9/Hx5t649NpzORmadfrrvn2CFtGHZob6FAG4aI/+5ldkQbhhxNU/hoHdEZclRrrUkN398Ky6tyPSKiMiRNdnr37o2KtvmRyWRISkpCUlKS0TpeXl5V2kCQ6jaFnR1adY/RKzOUBF1xbYvTWy/o3cG9JFlQQ4Ach7RhZU8NrYHy5MJOJiVGpW+Cauo5DNU1RPcTkpuvv+qg7GOg5Oaqn+xPL1eelVdQKmFSA1Dgq4vH4OmsLHeuym7GqtEKVSonIpJarZ2zQ1QVZZOgVgCiwxuW+/BNSctC4uY0g0mQod07DCVAFZUbUpW6llKVhKl8YlTC38OxVK9RgUnlM2NCUc/FgQkTEUmKyQ7ZLIVchohm3npl/Vv7G+yxMJQE3a+MJUbGeo0qKn9uzUm9MmslTIfTb+L4DRm8028i4gEfJlJE9zkmO3TfqSgJSr2Ugx0/H0bUQ12gKtBi7k9pJn0oV9Q7RPdYN2EqGaqzdM8TACZRRLUckx2i/yjkMnQJ9sI/5wV0CfaCUqlEdGvD81Ze6R/K3iGJVCdhslTPk7nmPAGGEyb2XhGZB5MdogoY6gUyVm5oiOzfO0XsHapDqpowmWPOk7GEqS70XjG5orqCyQ6RGRlKgmraO8QkqG6p6pynqqyqq029V8bOYc5eLVN7ryo6B5M0ApjsEFlcTXuHKkqCANM+hJgwkY45eq9M3+KgRM0SqYp7r2rWM3av3FwrB62d0BnDRE+fTKhoo5v7hEqlgoeHB/Ly8qp9b6ytW7di4MCBNr3d9/0QZ22OsaZ/0ZqaMDExIqpewmSpZKyqc8MM/axLOdRZeuGHLqEzF1M/v5nsgMmOqe6HOG09RkO/eIDyv6Sq+svSUDkRWY7uj5GyvWhlH1eHNYY6+7e+d4PvmjD185vDWET3kbIrznR/YZk6nGZsrpGh8qpMzmbCRFQ1VdkotKosPdQ5cdUJLB31oNkSHlMw2SEig6oy18hYeVUmZ1sqYWIiRVR7CCjplUrcnIZ+YX5Wmy/EZIeILEaqhMnQHAFLJFKc80RUdQJKen6OpN80+HvAEpjsEFGtVp2EydBQnSV6noxNzKzKnCdzrSZi7xXVNTm3rPe9ymSHiO5b5uh5Amo+5wkwvJKltvZecYsDMgcfN0erXYvJDhGRBdQ0YarsHFL3XlVlY0wplmWzB6z2kgHw87j3vWUNTHaIiGyYpXqvjNU1Z6+WKb1X1e0Zs9ZEeEsldMZ60YwtSa8tiZ5uOvLsQWFW3cyQyQ4REZmVuRIpU3uvKjqHtVYOSpHQGepF86vklh1SD3X6mXmfHVMx2SEiovueuXrArJnQVdSLVtE1rT3UackdlE3FZIeIiKiOMpYYmeMclkzorE0uyVWJiIiIrITJDhEREdk0JjtERERk05jsEBERkU1jskNEREQ2jckOERER2TQmO0RERGTTmOwQERGRTWOyQ0RERDaNOygDEISS26ipVKpqPV+tViM/Px8qlQpKpdKcTatV7oc4GaNtYIy2gTHaBkvGqPvc1n2OG8NkB8CtW7cAAIGBgRK3hIiIiKrq1q1b8PDwMHpcJlSWDt0HtFotrl+/Djc3N8hkVb9vh0qlQmBgIK5evQp3d3cLtLB2uB/iZIy2gTHaBsZoGywZoyAIuHXrFgICAiCXG5+Zw54dAHK5HI0aNarxedzd3W32m7W0+yFOxmgbGKNtYIy2wVIxVtSjo8MJykRERGTTmOwQERGRTWOyYwYODg6YPXs2HBwcpG6KRd0PcTJG28AYbQNjtA21IUZOUCYiIiKbxp4dIiIismlMdoiIiMimMdkhIiIim8Zkh4iIiGwakx0zWLx4MZo0aQJHR0d06dIFR44ckbpJ1bZ//34MGjQIAQEBkMlk2Lhxo95xQRAwa9Ys+Pv7w8nJCZGRkbh48aI0ja2m+fPno1OnTnBzc4OPjw+GDBmCCxcu6NUpKChAQkICvL294erqitjYWGRnZ0vU4qpbunQp2rRpI27iFRERgW3btonH63p8hrz11luQyWSYPHmyWFbX45wzZw5kMpneV0hIiHi8rsen89dff2HUqFHw9vaGk5MTwsPDcezYMfF4Xf+906RJk3Lvo0wmQ0JCAgDbeB81Gg1mzpyJ4OBgODk5oVmzZpg7d67ePaskfR8FqpFvv/1WsLe3F7744gvh3Llzwvjx4wVPT08hOztb6qZVy9atW4Xp06cL69evFwAIGzZs0Dv+1ltvCR4eHsLGjRuF06dPC48++qgQHBws3L17V5oGV0N0dLSwYsUK4ezZs8KpU6eEgQMHCo0bNxZu374t1nn22WeFwMBAYdeuXcKxY8eErl27Ct26dZOw1VWzadMm4aeffhJ+//134cKFC8Lrr78uKJVK4ezZs4Ig1P34yjpy5IjQpEkToU2bNsKLL74oltf1OGfPni20atVKyMzMFL/+/vtv8Xhdj08QBOHmzZtCUFCQMGbMGOHw4cPC5cuXheTkZOHSpUtinbr+eycnJ0fvPUxJSREACHv27BEEwTbex3nz5gne3t7Cli1bhPT0dGHdunWCq6ur8OGHH4p1pHwfmezUUOfOnYWEhATxsUajEQICAoT58+dL2CrzKJvsaLVawc/PT3jnnXfEstzcXMHBwUH45ptvJGiheeTk5AgAhH379gmCUBKTUqkU1q1bJ9Y5f/68AEBITU2Vqpk1Vq9ePeHzzz+3ufhu3bolNG/eXEhJSRF69eolJju2EOfs2bOFtm3bGjxmC/EJgiC8+uqrQo8ePYwet8XfOy+++KLQrFkzQavV2sz7GBMTI4wbN06vbNiwYUJcXJwgCNK/jxzGqoGioiIcP34ckZGRYplcLkdkZCRSU1MlbJllpKenIysrSy9eDw8PdOnSpU7Hm5eXBwDw8vICABw/fhxqtVovzpCQEDRu3LhOxqnRaPDtt9/izp07iIiIsLn4EhISEBMToxcPYDvv48WLFxEQEICmTZsiLi4OGRkZAGwnvk2bNqFjx454/PHH4ePjg/bt2+Ozzz4Tj9va752ioiKsWrUK48aNg0wms5n3sVu3bti1axd+//13AMDp06fxyy+/YMCAAQCkfx95I9AauHHjBjQaDXx9ffXKfX198dtvv0nUKsvJysoCAIPx6o7VNVqtFpMnT0b37t3RunVrACVx2tvbw9PTU69uXYvzzJkziIiIQEFBAVxdXbFhwwaEhYXh1KlTNhEfAHz77bc4ceIEjh49Wu6YLbyPXbp0wcqVK9GyZUtkZmYiMTERDz30EM6ePWsT8QHA5cuXsXTpUkyZMgWvv/46jh49ihdeeAH29vaIj4+3ud87GzduRG5uLsaMGQPANr5PAeC1116DSqVCSEgIFAoFNBoN5s2bh7i4OADSf34w2aH7WkJCAs6ePYtffvlF6qaYXcuWLXHq1Cnk5eXh+++/R3x8PPbt2yd1s8zm6tWrePHFF5GSkgJHR0epm2MRur+KAaBNmzbo0qULgoKCsHbtWjg5OUnYMvPRarXo2LEj3nzzTQBA+/btcfbsWSxbtgzx8fESt878li9fjgEDBiAgIEDqppjV2rVrsXr1aqxZswatWrXCqVOnMHnyZAQEBNSK95HDWDVQv359KBSKcrPms7Oz4efnJ1GrLEcXk63EO2nSJGzZsgV79uxBo0aNxHI/Pz8UFRUhNzdXr35di9Pe3h4PPPAAOnTogPnz56Nt27b48MMPbSa+48ePIycnBw8++CDs7OxgZ2eHffv2YdGiRbCzs4Ovr69NxFmap6cnWrRogUuXLtnM++jv74+wsDC9stDQUHG4zpZ+71y5cgU7d+7E008/LZbZyvv48ssv47XXXsPIkSMRHh6O0aNH46WXXsL8+fMBSP8+MtmpAXt7e3To0AG7du0Sy7RaLXbt2oWIiAgJW2YZwcHB8PPz04tXpVLh8OHDdSpeQRAwadIkbNiwAbt370ZwcLDe8Q4dOkCpVOrFeeHCBWRkZNSpOMvSarUoLCy0mfj69u2LM2fO4NSpU+JXx44dERcXJ/7fFuIs7fbt2/jjjz/g7+9vM+9j9+7dy2398PvvvyMoKAiA7fzeAYAVK1bAx8cHMTExYpmtvI/5+fmQy/VTCoVCAa1WC6AWvI8WnwJt47799lvBwcFBWLlypZCWliZMmDBB8PT0FLKysqRuWrXcunVLOHnypHDy5EkBgPD+++8LJ0+eFK5cuSIIQsnSQU9PT+HHH38Ufv31V2Hw4MF1agmoIAjCxIkTBQ8PD2Hv3r16y0Hz8/PFOs8++6zQuHFjYffu3cKxY8eEiIgIISIiQsJWV81rr70m7Nu3T0hPTxd+/fVX4bXXXhNkMpmwY8cOQRDqfnzGlF6NJQh1P87//e9/wt69e4X09HThwIEDQmRkpFC/fn0hJydHEIS6H58glGwbYGdnJ8ybN0+4ePGisHr1asHZ2VlYtWqVWMcWfu9oNBqhcePGwquvvlrumC28j/Hx8ULDhg3Fpefr168X6tevL7zyyitiHSnfRyY7ZvDRRx8JjRs3Fuzt7YXOnTsLhw4dkrpJ1bZnzx4BQLmv+Ph4QRBKlg/OnDlT8PX1FRwcHIS+ffsKFy5ckLbRVWQoPgDCihUrxDp3794VnnvuOaFevXqCs7OzMHToUCEzM1O6RlfRuHHjhKCgIMHe3l5o0KCB0LdvXzHREYS6H58xZZOduh7niBEjBH9/f8He3l5o2LChMGLECL39Z+p6fDqbN28WWrduLTg4OAghISHCp59+qnfcFn7vJCcnCwAMttsW3keVSiW8+OKLQuPGjQVHR0ehadOmwvTp04XCwkKxjpTvo0wQSm1vSERERGRjOGeHiIiIbBqTHSIiIrJpTHaIiIjIpjHZISIiIpvGZIeIiIhsGpMdIiIismlMdoiIiMimMdkhIgIgk8mwceNGqZtBRBbAZIeIJDdmzBjIZLJyX/3795e6aURkA+ykbgAREQD0798fK1as0CtzcHCQqDVEZEvYs0NEtYKDgwP8/Pz0vurVqwegZIhp6dKlGDBgAJycnNC0aVN8//33es8/c+YM+vTpAycnJ3h7e2PChAm4ffu2Xp0vvvgCrVq1goODA/z9/TFp0iS94zdu3MDQoUPh7OyM5s2bY9OmTeKxf//9F3FxcWjQoAGcnJzQvHnzcskZEdVOTHaIqE6YOXMmYmNjcfr0acTFxWHkyJE4f/48AODOnTuIjo5GvXr1cPToUaxbtw47d+7US2aWLl2KhIQETJgwAWfOnMGmTZvwwAMP6F0jMTERw4cPx6+//oqBAwciLi4ON2/eFK+flpaGbdu24fz581i6dCnq169vvReAiKrPKrcbJSKqQHx8vKBQKAQXFxe9r3nz5gmCUHKn+meffVbvOV26dBEmTpwoCIIgfPrpp0K9evWE27dvi8d/+uknQS6XC1lZWYIgCEJAQIAwffp0o20AIMyYMUN8fPv2bQGAsG3bNkEQBGHQoEHC2LFjzRMwEVkV5+wQUa3w8MMPY+nSpXplXl5e4v8jIiL0jkVERODUqVMAgPPnz6Nt27ZwcXERj3fv3h1arRYXLlyATCbD9evX0bdv3wrb0KZNG/H/Li4ucHd3R05ODgBg4sSJiI2NxYkTJxAVFYUhQ4agW7du1YqViKyLyQ4R1QouLi7lhpXMxcnJyaR6SqVS77FMJoNWqwUADBgwAFeuXMHWrVuRkpKCvn37IiEhAe+++67Z20tE5sU5O0RUJxw6dKjc49DQUABAaGgoTp8+jTt37ojHDxw4ALlcjpYtW8LNzQ1NmjTBrl27atSGBg0aID4+HqtWrcIHH3yATz/9tEbnIyLrYM8OEdUKhYWFyMrK0iuzs7MTJwGvW7cOHTt2RI8ePbB69WocOXIEy5cvBwDExcVh9uzZiI+Px5w5c/D333/j+eefx+jRo+Hr6wsAmDNnDp599ln4+PhgwIABuHXrFg4cOIDnn3/epPbNmjULHTp0QKtWrVBYWIgtW7aIyRYR1W5MdoioVti+fTv8/f31ylq2bInffvsNQMlKqW+//RbPPfcc/P398c033yAsLAwA4OzsjOTkZLz44ovo1KkTnJ2dERsbi/fff188V3x8PAoKCrBw4UJMnToV9evXx2OPPWZy++zt7TFt2jT8+eefcHJywkMPPYRvv/3WDJETkaXJBEEQpG4EEVFFZDIZNmzYgCFDhkjdFCKqgzhnh4iIiGwakx0iIiKyaZyzQ0S1Hkfbiagm2LNDRERENo3JDhEREdk0JjtERERk05jsEBERkU1jskNEREQ2jckOERER2TQmO0RERGTTmOwQERGRTWOyQ0RERDbt/wFuJoTiORGD2wAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["train_loss_array = np.load(f\"/content/drive/MyDrive/P3DCV/losses/train/difffmap_1.76573.npy\")\n","val_loss_array = np.load(f\"/content/drive/MyDrive/P3DCV/losses/val/difffmap_1.76573.npy\")\n","epochs = np.arange(1, len(train_loss_array) + 1)\n","\n","plt.plot(epochs, train_loss_array, label='Train Loss', marker='o')\n","plt.plot(epochs, val_loss_array, label='Validation Loss', marker='o')\n","\n","plt.title('Train and Validation Loss Curve')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LI4-Yjk7iqPI"},"outputs":[],"source":["#test loops\n","for epoch in range(n_epoch):\n","    train_losses = []\n","    eval_losses = []\n","    faust_losses = []\n","    metrics = []\n","    # Training single Epoch\n","    for i, data in enumerate(train_loader):\n","        vertsA, vertsB = data\n","        batch = vertsA.shape[0]\n","        vertsA = vertsA.to(device).to(torch.float32)\n","        vertsB = vertsB.to(device).to(torch.float32)\n","        cat_verts = torch.cat([vertsA.transpose(1,2), vertsB.transpose(1,2)], dim=0)\n","        optim.zero_grad()\n","        basisNet = basisNet.train()\n","\n","        # Obtaining predicted basis\n","        cat_preds, _, _ = basisNet(cat_verts)#cat_pred.shape (B, n_points, k)\n","\n","        basisA = cat_preds[:batch, :, :]\n","        basisB = cat_preds[batch:, :, :]\n","        # Computing optimal transformation\n","        pseudo_inv_A = torch.pinverse(basisA)\n","        C_opt = torch.matmul(pseudo_inv_A, basisB)\n","        opt_A = torch.matmul(basisA, C_opt)\n","\n","        # SoftMap\n","        dist_matrix = torch.cdist(opt_A, basisB)\n","        s_max = torch.nn.Softmax(dim=1)\n","        s_max_matrix = s_max(-dist_matrix)\n","\n","        # Basis Loss\n","        eucl_loss = torch.sum(torch.square(torch.matmul(s_max_matrix, vertsB) - vertsB))\n","\n","        #metric = torch.mean(torch.square(s_max_matrix - torch.identity(s_max_matrix.shape[0]))) # measuring how well we are approximating the ground-truth correspondence\n","        # Back Prop\n","        eucl_loss.backward()\n","        optim.step()\n","        train_losses.append(eucl_loss.detach().item())\n","        #metrics.append(metric.detach().item())\n","    ave_train_loss = sum(train_losses) / len(train_losses)\n","    #ave_metric = sum(metrics) / len(metrics)\n","    print(f\"training loss for epoch{epoch}:\", ave_train_loss)\n","    #print(f\"training metric for epoch{epoch}:\", ave_metric)\n","    torch.save(basisNet.state_dict(), f\"/content/drive/MyDrive/P3DCV/models/difffmap_resampled_epoch_{epoch}.pt\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BCOO62564bKB"},"outputs":[],"source":["'''\n","\n","    # Validation\n","    with torch.no_grad():\n","        eval_loss = 0\n","        for data in tqdm(dataset_test, 0):\n","            points = data[0]\n","            points = points.transpose(2, 1)\n","            points = points.cuda()\n","            basisNet = basisNet.eval()\n","            pred, _, _ = basisNet(points)\n","            basis_A = pred[1:,:,:]; basis_B = pred[:-1,:,:]\n","            pc_A = points[1:,:,:]; pc_B = points[:-1,:,:]\n","\n","            pseudo_inv_A = torch.pinverse(basis_A)\n","            C_opt = torch.matmul(pseudo_inv_A, basis_B)\n","            opt_A = torch.matmul(basis_A, C_opt)\n","\n","            dist_matrix = torch.cdist(opt_A, basis_B)\n","            s_max = torch.nn.Softmax(dim=1)\n","            s_max_matrix = s_max(-dist_matrix)\n","            eucl_loss = torch.sum(torch.square(torch.matmul(s_max_matrix, torch.transpose(pc_B,1,2)) - torch.transpose(pc_B,1,2)))\n","            eval_loss +=   eucl_loss.item()\n","\n","        print('EPOCH ' + str(epoch) + ' - eva_loss: ' + str(eval_loss))\n","\n","        # Saving if best model so far\n","        if eval_loss <  best_eval_loss:\n","            print('save model')\n","            best_eval_loss = eval_loss\n","            torch.save(basisNet.state_dict(), '%s/basis_model_best.pth' % (outf))\n","\n","        train_losses.append(train_loss)\n","        eval_losses.append(eval_loss)\n","\n","        # Logging losses\n","        np.save(outf+'/train_losses_basis.npy',train_losses)\n","        np.save(outf+'/eval_losses_basis.npy',eval_losses)\n","'''"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"V100"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}